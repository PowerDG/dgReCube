

## 网络知识

最具代表性大规模网络知识获取的 工作包括DBpedia、Freebase、KnowItAll、WikiTaxonomy和YAGO，以及BabelNet、ConceptNet、 DeepDive、NELL、Probase、Wikidata、XLORE、[http://Zhishi.me](https://link.zhihu.com/?target=http%3A//Zhishi.me)、CNDBpedia 等。这些知识图谱 遵循 RDF 数据模型，包含数以千万级或者亿级规模的实体，以及数十亿或百亿事实（即属 性值和与其他实体的关系），并且这些实体被组织在成千上万的由语义体现的客观世界的概 念结构中。



# 知识图谱技术解剖



https://www.jianshu.com/p/bd15e0f50eb9

https://blog.csdn.net/u010159842/article/details/88026675



最全知识图谱介绍:关键技术、开放数据集、应用案例汇总

https://www.jianshu.com/p/995cc0b8ebe5

本体、知识库、知识图谱、知识图谱识别之间的关系？

本体：领域术语集合。

知识库：知识集合。

知识图谱：图状具有关联性的知识集合。

### 知识图谱@语义网络

知识图谱本质上是语义网络，是一种基于图的数据结构，由**节点(Point)和边(Edge)**组成。在知识图谱里，每个节点表示现实世界中存在的**“实体”**，每条边为实体与实体之间的**“关系”**。知识图谱是关系的最有效的表示方式。通俗地讲，知识图谱就是把所有**不同种类的信息连接在一起而得到的一个关系网络**。知识图谱提供了**从“关系”的角度去分析问题**的能力。

构建知识图谱的主要目的是获取大量的、让计算机可读的知识。但是**构建知识图谱的重点在于语义理解、知识表示、QA、智能对话和用户建模**。但从抽象层面看，本体最抽象，其次是知识库，最后才是知识图谱。

### 知识数据库

知识库就是一个知识数据库，包含了知识的本体和知识。

比如Freebase是一个知识库（结构化），维基百科也可以看成一个知识库（半结构化），等等。

也就是说，本体是强调**概念关系**，知识图谱强调**实体关系和实体属性值**，知识库则是所有知识的集合。但是知识库不局限于分类和图谱，知识库可以包括**规则**，包括**过程性知识等**。而本体也可以定义得很抽象，任何概念的内涵和外延可以定义本体。

![img](https:////upload-images.jianshu.io/upload_images/3455530-ee18e1f2d367b93b.png?imageMogr2/auto-orient/strip|imageView2/2/w/762)

知识图谱部署成本

### 数据的处理方法

知识图谱是一系列结构化数据的处理方法，它涉及**知识的提取、 表示、存储、检索等诸多技术。**从渊源上讲，它是**知识表示与推理、数据库、信息检索、自然语言处理**等多种技术发展的融合。 但传统的知识处理方法，在实际的工程应用，特别是互联网应用中，面临实施成本高、技术周期长、熟悉该类技术的人才缺乏、 基础数据不足等诸多现实制约。实战中的知识图谱，需要充分利用成熟的工业技术，不拘泥于特定的工具和方法，特别是不盲目追求标准化、技术的先进性或者新颖性，以实际的业务出发，循序渐进推进工程的实施。

### 全周期成本

知识图谱的全周期成本:有哪些成本？分为**技术成本、团队成本和组织成本**。技术有知识提取的成本、知识存储的成本、知识推理的成本、知识检索的成本、运维的成本、更新的成本。教育成本，一个人进来之后，他到底是一个月之后就能干活，还是半年之后能干活，**取决于你的技术架构**。如果你的知识提取架构是以正则表达式为基础的，那可能很容易。如果你是以一个规则的神经网络分布式表示来做，可能要半年之后才能理解是什么，所以这都是成本。

## 知识图谱和专家系统有什么异同点？

专家系统一般来说是基于规则的，专家系统的知识更多的是人工构建，知识图谱可以作为专家系统的一部分存在，提供半自动构建知识库的方法。要说共同点都是人工智能的应用，肯定有很多共有技术的，不同点可能就是根据不同的场景特意的技术运用。

**知识图谱： 他是迈向下一代搜索业务关键的第一步，使得搜索智能化，根据用户的意图给出用户想要的结果。**

特点：

1、用户搜索次数越多，范围越广，Google 就能获取越多信息和内容。

2、赋予字串新的意义，而不只是单纯的字串。

3、融合了所有的学科，以便于用户搜索时的连贯性。

4、为用户找出更加准确的信息，作出做全面的总结并提供更有深度相关的信息。

5、把与关键词相关的知识体系系统化地展示给用户。

6、用户只需登录Google旗下60多种在线服务中的一种就能获取在其他服务上保留的信息和数据。

7、Google从整个互联网汲取有用的信息让用户能够获得更多相关的公共资源。

**专家系统： 是一种模拟人类专家解决领域问题的计算机程序系统 。**

特点：专家系统是一个具有大量的专门知识与经验的程序系统，它应用人工智能技术和计算机技术，根据某领域一个或多个专家提供的知识和经验，进行推理和判断，模拟人类专家的决策过程，以便解决那些需要人类专家处理的复杂问题。

![img](https:////upload-images.jianshu.io/upload_images/3455530-f15a3f7ec4a88518.png?imageMogr2/auto-orient/strip|imageView2/2/w/621)

**什么叫专家系统？就是人去学一个东西，然后把学到的知识理论化，再把这些理论模型化，最后把这个模型程序化，形成一个系统，就叫专家系统。**

## 知识图谱分为三个部分技术组成：

第一个部分是知识获取，主要阐述如何从非结构化、半结构化、以及结构化数据中获取知识。

第二部是数据融合，主要阐述如何将不同数据源获取的知识进行融合构建数据之间的关联。

第三部分是知识计算及应用，这一部分关注的是基于知识图谱计算功能以及基于知识图谱的应用。

## 1 知识图谱构建技术

### **1.1 知识图谱技术地图**

### 1.1.1 知识获取

在处理非结构化数据方面，首先要对用户的非结构化数据提取正文。目前的互联网数据存在着大量的广告，正文提取技术希望有效的过滤广告而只保留用户关注的文本内容。当得到正文文本后，需要通过自然语言技术**识别文章中的实体**，实体识别通常有两种方法，一种是用户本身有一个知识库则可以使用**实体链接**将文章中可能的**候选实体链接****到用户的知识库上。另一种是当用户没有知识库则需要使用**命名实体识别技术**识别文章中的实体。

若文章中存在实体的别名或者简称还需要构建实体间的同义词表，这样可以使不同实体具有相同的描述。在识别实体的过程中可能会用到分词、词性标注，以及深度学习模型中需要用到分布式表达如词向量。同时为了得到不同粒度的知识还可能需要提取文中的关键词，获取文章的潜在主题等。当用户获得实体后，则需要关注实体间的关系，我们称为实体关系识别，有些实体关系识别的方法会利用句法结构来帮助确定两个实体间的关系，因此在有些算法中会利用依存分析或者语义解析。如果用户不仅仅想获取实体间的关系，还想获取一个事件的详细内容，那么则需要确定事件的触发词并获取事件相应描述的句子，同时识别事件描述句子中实体对应事件的角色。

在处理半结构化数据方面，主要的工作是通过包装器学习半结构化数据的抽取规则。由于半结构化数据具有大量的重复性的结构，因此对数据进行少量的标注，可以让机器学出一定的规则进而在整个站点下使用规则对同类型或者符合某种关系的数据进行抽取。最后当用户的数据存储在生产系统的数据库中时，需要通过 ETL 工具对用户生产系统下的数据进行重新组织、清洗、检测最后得到符合用户使用目的数据。

![img](https:////upload-images.jianshu.io/upload_images/3455530-bf7517113e03bbe1.png?imageMogr2/auto-orient/strip|imageView2/2/w/624)

### 1.1.2 知识融合

当知识从各个数据源下获取时需要提供统一的术语将各个数据源获取的知识融合成一个庞大的知识库。提供统一术语的结构或者数据被称为本体，本体不仅提供了统一的术语字典，还构建了各个术语间的关系以及限制。本体可以让用户非常方便和灵活的根据自己的业务建立或者修改数据模型。通过数据映射技术建立本体中术语和不同数据源抽取知识中词汇的映射关系，进而将不同数据源的数据融合在一起。

同时不同源的实体可能会指向现实世界的同一个客体，这时需要使用实体匹配将不同数据源相同客体的数据进行融合。不同本体间也会存在某些术语描述同一类数据，那么对这些本体间则需要本体融合技术把不同的本体融合。最后融合而成的知识库需要一个存储、管理的解决方案。

知识存储和管理的解决方案会根据用户查询场景的不同采用不同的存储架构如 NoSQL 或者关系数据库。同时大规模的知识库也符合大数据的特征，因此需要传统的大数据平台如 Spark 或者 Hadoop 提供高性能计算能力，支持快速运算。

### **1.1.2 知识计算及应用**



知识计算主要是根据图谱提供的信息得到更多隐含的知识，如通过本体或者规则推理技术可以获取数据中存在的隐含知识；而链接预测则可预测实体间隐含的关系；同时使用社会计算的不同算法在知识网络上计算获取知识图谱上存在的社区，提供知识间关联的路径；通过不一致检测技术发现数据中的噪声和缺陷。通过知识计算知识图谱可以产生大量的智能应用如可以提供精确的用户画像为精准营销系统提供潜在的客户；提供领域知识给专家系统提供决策数据，给律师、医生、公司 CEO 等提供辅助决策的意见；提供更智能的检索方式，使用户可以通过自然语言进行搜索；当然知识图谱也是问答必不可少的重要组建。

### **1.2　实体关系识别技术**

基于统计学的方法将从文本中识别实体间关系的问题转化为分类问题。基于统计学的方法在实体关系识别时需要加入实体关系上下文信息确定实体间的关系，然而基于监督的方法依赖大量的标注数据，因此半监督或者无监督的方法受到了更多关注。

### **1.3　知识融合技术**



知识融合指的是将多个数据源抽取的知识进行融合。与传统数据融合任务的主要不同是，知识融合可能使用多个知识抽取工具为每个数据项从每个数据源中抽取相应的值，而数据融合未考虑多个抽取工具。由此，知识融合除了应对抽取出来的事实本身可能存在的噪音外，还比数据融合多引入了一个噪音，就是不同抽取工具通过实体链接和本体匹配可能产生不同的结果。另外，知识融合还需要考虑本体的融合和实例的融合。

首先从已有的数据融合方法中挑选出易于产生有意义概率的、便于使用基于 MapReduce 框架的、有前途的最新方法，然后对这些挑选出的方法做出以下改进以用于知识融合：将每个抽取工具同每个信息源配对，每对作为数据融合任务中的一个数据源，这样就变成了传统的数据融合任务；改进已有数据融合方法使其输出概率，代替原来的真假二值；根据知识融合中的数据特征修改基于 MapReduce 的框架。可以将通过不同搜索引擎得到的知识卡片（即结构化的总结）融合起来的方法。

![img](https:////upload-images.jianshu.io/upload_images/3455530-8c451d36807a3bdf.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/398)

针对一个实体查询，不同搜索引擎可能返回不同的知识卡片，即便同一个搜索引擎也可能返回多个知识卡片。将这些知识卡片融合起来时，将知识融合中的三维问题将为二维问题，再应用传统的数据融合技术。不过一个新的概率打分算法，是用于挑选一个知识卡片最有可能指向的实体，并设计了一个基于学习的方法来做属性匹配。

在知识融合技术中，本体匹配扮演着非常重要的角色，提供了概念或者实体之间的对应关系。截止目前，人们已经提出了各种各样的本体匹配算法，一般可以分为模式匹配（schema matching）和实例匹配（instance matching），也有少量的同时考虑模式和实例的匹配[32-34]。从技术层面来讲，本体匹配可分为启发式方法、概率方法、基于图的方法、基于学习的方法和基于推理的方法。下面围绕模式匹配和实例匹配，具体介绍各自分类中几个具有代表性的匹配方法。

模式匹配主要寻找本体中属性和概念之间的对应关系，一个自动的语义匹配方法，该方法首先利用像 WordNet 之类的词典以及本体的结构等信息进行模式匹配，然后将结果根据加权平均的方法整合起来，再利用一些模式（patterns）进行一致性检查，去除那些导致不一致的对应关系。该过程可循环的，直到不再找到新的对应关系为止。考虑多种匹配算法的结合，利用基于术语的一些相似度计算算法，例如 n-gram 和编辑距离，这里算法计算的结果根据加权求和进行合并，还考虑了概念的层次关系和一些背景知识，最后通过用户定义的权重进行合并。

为了应对大规模的本体，使用锚（anchor）的系统，该系统以一对来自两个本体的相似概念为起点，根据这些概念的父概念和子概念等邻居信息逐渐地构建小片段，从中找出匹配的概念。新找出的匹配的概念对又可作为新的锚，然后再根据邻居信息构建新的片段。该过程不断地重复，直到未找到新的匹配概念对时停止。则以分而治之的思想处理大规模本体，该方法先根据本体的结构对其进行划分获得组块，然后从不同本体获得的组块进行基于锚的匹配，这里的锚是指事先匹配好的实体对，最后再从匹配的组块中找出对应的概念和属性。

![img](https:////upload-images.jianshu.io/upload_images/3455530-2040401aa4d9844f.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/628)

现有的匹配方法通常是将多个匹配算法相结合，采用加权平均或加权求和的方式进行合并。但是，由于本体结构的不对称性等特征，这种固定的加权方法显出不足。基于贝叶斯决策的风险最小化提出一个动态的合并方法，该方法可以根据本体的特征，在计算每个实体对的相似度时动态地选择使用哪几个匹配算法，如何合并这些算法，其灵活性带来了很好的匹配结果。实例匹配是评估异构知识源之间实例对的相似度，用来判断这些实例是否指向给定领域的相同实体。

最近几年，随着 Web 2.0 和语义 Web 技术的不断发展，越来越多的语义数据往往具有丰富实例和薄弱模式的特点，促使本体匹配的研究工作慢慢的从模式层转移到实例层。一个自训练的方法进行实例匹配，该方法首先根据 owl:sameAs、函数型属性（functional properties）和基数（cardinalities）构建一个核（kernel），再根据区别比较明显的属性值对递归的对该核进行扩展。利用现有的局部敏感哈希技术来大幅提高实例匹配的可扩展性，该方法首先需要定义用于实例相似性分析的粒度，然后使用分割好的字符串技术实例相似度。

首先使用向量空间模型表示实例的描述性信息，再基于规则采用倒排索引（inverted indexes）获取最初的匹配候选，在使用用户定义的属性值对候选进行过滤，最后计算出的匹配候选相似度用来作为整合的向量距离，由此抽取出匹配结果。虽然已有方法中已有不少用于处理大规模本体的实例匹配问题，但是同时保证高效和高精度仍然是个很大的挑战。一个迭代的框架，充分利用特征明显的已有匹配方法来提高效率，同时基于相似度传播的方法利用一个加权指数函数来确保实例匹配的高精度。

![img](https:////upload-images.jianshu.io/upload_images/3455530-4b6b989dd9d24053.png?imageMogr2/auto-orient/strip|imageView2/2/w/754)

### **1.4　实体链接技术**

歧义性和多样性是自然语言的固有属性，也是实体链接的根本难点。如何挖掘更多、更加有效的消歧证据，设计更高性能的消歧算法依然是实体链接系统的核心研究问题，值得进一步研究。下面按照不同的实体消歧方法进行分类。

基于概率生成模型方法：一种生成概率模型，将候选实体 e 出现在某页面中的概率、特定实体 e 被表示为实体指称项的概率以及实体 e 出现在特定上下文中的概率三者相乘，得到候选实体同实体指称项之间的相似度评分值。Blanco 和 Ottaviano 等人[48]提出了用于搜索查询实体链接的概率模型，该方法采用了散列技术与上下文知识，有效地提高了实体链接的效率。

基于主题模型的方法：通过模型自动对文本中的实体指称进行标注，生成训练数据集用于训练 LDA 主题模型，然后计算实体指称和候选实体的上下文语义相似度从而消歧得到目标实体。对用户的兴趣主题建模的方法，首先构建关系图，图中包含了不同命名实体间的相互依赖关系，然后利用局部信息对关系图中每个命名实体赋予初始兴趣值，最后利用传播算法对不同命名实体的兴趣值进行传播得到最终兴趣值，选择具有最高兴趣值的候选实体。

基于图的方法：构造了一种基于图的模型，其中图节点为所有实体指称和所有候选实体；图的边分为两类，一类是实体指称和其对应的候选实体之间的边，权重为实体指称和候选实体之间的局部文本相似度，采用词袋模型和余弦距离计算得出。另一类是候选实体之间的边，权重为候选实体之间的语义相关度，采用谷歌距离计算。算法首先采集不同实体的初始置信度，然后通过图中的边对置信度进行传播和增强。

基于图和语义关系的命名实体消歧方法，该方法在维基百科上建立基于图的模型，然后在该模型上计算各个命名实体的得分从而确定了目标实体，该方法在新闻数据上取得了较高的准确率。采用基于图的方法，图中的节点为所有的候选实体，边采用两种方式构建，一种是实体之间的维基百科链接，另一种是使用实体在维基百科文章中句子的共现。图中的候选实体节点通过和实体指称的相似度值被赋予初始值，采用 PageRank 选择目标实体。使用实体的先验概率，实体指称和候选实体的上下文相似度，以及候选实体之间的内聚性构成一个加权图，从中选择出一个候选实体的密集子图作为最可能的目标实体分配给实体指称。

![img](https:////upload-images.jianshu.io/upload_images/3455530-240422c2db0f5977.png?imageMogr2/auto-orient/strip|imageView2/2/w/752)

基于深度神经网络的方法：一种用于实体消歧的实体表示训练方法。该方法对文章内容进行自编码，利用深度神经网络模型以有监督的方式训练实体表示，依据语义表示相似度对候选实体进行排序，但该方法是一种局部性方法，没有考虑同一文本中共同出现的实体间相关性。基于深度神经网络和语义知识图谱，提出了一种基于图的半监督实体消歧义方法，将深度神经网络模型得到的实体间语义关联度作为图中的边权值。

从实验结果得出：基于语义知识图谱的 NGD 和VSM方法比起 Wikipedia anchor links 无论在关联性测试上还是在消歧性能上都具有更好的测试结果。相比 NGD 和 VSM，基于 DNN的深度语义关联方法在关联性测试上还是在消歧性能上都具有更好的关联性和更高的准确性。但该方法存在两点不足，一方面在构建深度语义关联模型时采用词袋子方法，没有考虑上下文词之间位置关系，另外一方面在消歧的过程中，构建的图模型没有充分利用已消歧实体，边权值和顶点得分随着未消歧实体增加保持不变，并没有为后续的歧义实体增加信息量。

![img](https:////upload-images.jianshu.io/upload_images/3455530-ddf8982d9ab49a87.png?imageMogr2/auto-orient/strip|imageView2/2/w/754)

### **1.5　知识推理技术**



知识库推理可以粗略地分为基于符号的推理和基于统计的推理。在人工智能的研究中，基于符号的推理一般是基于经典逻辑（一阶谓词逻辑或者命题逻辑）或者经典逻辑的变异（比如说缺省逻辑）。基于符号的推理可以从一个已有的知识图谱，利用规则，推理出新的实体间关系，还可以对知识图谱进行逻辑的冲突检测。基于统计的方法一般指关系机器学习方法，通过统计规律从知识图谱中学习到新的实体间关系。

### **1.5.1 基于符号逻辑的推理方法**

为了使得语义网络同时具备形式化语义和高效推理，一些研究人员提出了易处理（tractable）概念语言，并且开发了一些商用化的语义网络系统。这些系统的提出，使得针对概念描述的一系列逻辑语言，统称描述逻辑（description logic），得到了学术界和业界广泛关注。但是这些系统的推理效率难以满足日益增长的数据的需求，最终没能得到广泛应用。这一困局被利物浦大学的 Ian Horrocks 教授打破，他开发的 FaCT 系统可以处理一个比较大的医疗术语本体 GALEN，而且性能比其他类似的推理机要好得多。描述逻辑最终成为了 W3C 推荐的 Web 本体语言 OWL 的逻辑基础。

虽然描述逻辑推理机的优化取得了很大的进展，但是还是跟不上数据增长的速度，特别是当数据规模大到目前的基于内存的服务器无法处理的情况下。为了应对这一挑战，最近几年，研究人员开始考虑将描述逻辑和 RDFS 的推理并行来提升推理的效率和可扩展性，并且取得了很多成果。并行推理工作所借助的并行技术分为以下两类：1）单机环境下的多核、多处理器技术，比如多线程，GPU 技术等；2）多机环境下基于网络通信的分布式技术，比如 MapReduce 计算框架、Peer-To-Peer 网络框架等。很多工作尝试利用这些技术实现高效的并行推理。

![img](https:////upload-images.jianshu.io/upload_images/3455530-a29cfd8f3b305a3e.png?imageMogr2/auto-orient/strip|imageView2/2/w/758)

单机环境下的并行技术以共享内存模型为特点，侧重于提升本体推理的时间效率。对于实时性要求较高的应用场景，这种方法成为首选。对于表达能力较低的语言，比如 RDFS、OWL EL，单机环境下的并行技术将显著地提升本体推理效率。Goodman 等人在[59]中利用高性能计算平台 Cray XMT 实现了大规模的 RDFS 本体推理，利用平台计算资源的优势限制所有推理任务在内存完成。

然而对于计算资源有限的平台，内存使用率的优化成为了不可避免的问题。工作中将 RDFS，以及表达能力更高的 OWL RL 等价地转换为 Datalog 程序，然后利用 Datalog 中的并行优化技术来解决内存的使用率问题。利用并行与串行的混合方法来提升OWL RL的推理效率，利用多线程技术实现 OWL EL 分类(classification)的方法，并实现推理机 ELK。

尽管单机环境的推理技术可以满足高推理性能的需求，但是由于计算资源有限（比如内存，存储容量），推理方法的可伸缩性（scalability）受到不同程度的限制。因此，很多工作利用分布式技术突破大规模数据的处理界限。这种方法利用多机搭建集群来实现本体推理。

![img](https:////upload-images.jianshu.io/upload_images/3455530-20eee412a33048d7.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/400)

首个尝试利用 Peer-To-Peer 的分布式框架实现 RDF 数据推理的工作。实验结果表明，利用分布式技术可以完成很多在单机环境下无法完成的大数据量推理任务。很多工作基于 MapReduce 的开源实现（如 Hadoop，Spark 等）设计提出了大规模本体的推理方法。实验结果证实其在大集群上可以完成上百亿的 RDF 三元组的推理。基于 MapReduce 的 OWL RL 查询算法利用 MapReduce 来实现 OWL EL 本体的推理算法在实验证明 MapReduce 技术同样可以解决大规模的 OWL EL 本体推理。工作中，进一步扩展 OWL EL 的推理技术，使得推理可以在多个并行计算平台完成。

### **1.5.2 基于统计的推理方法**



知识图谱中基于统计的推理方法一般指关系机器学习方法。下面介绍一些典型的方法。

### **实体关系学习方法**



实体关系学习的目的是学习知识图谱中实例和实例之间的关系。这方面的工作非常多，也是最近几年知识图谱的一个比较热的研究方向。可以分为潜在特征模型和图特征模型两种。潜在特征模型通过实例的潜在特征来解释三元组。比如说，莫言获得诺贝尔文学奖的一个可能解释是他是一个有名的作家。一个关系潜在特征模型，称为双线性（bilinear）模型，该模型考虑了潜在特征的两两交互来学习潜在的实体关系。应用两两交互的张量分解模型来学习知识图谱中的潜在关系。

翻译（translation）模型将实体与关系统一映射至低维向量空间中，且认为关系向量中承载了头实体翻译至尾实体的潜在特征。因此，通过发掘、对比向量空间中存在类似潜在特征的实体向量对，我们可以得到知识图谱中潜在的三元组关系。全息嵌入（Holographic Embedding，HolE）模型分别利用圆周相关计算三元组的组合表示及利用圆周卷积从组合表示中恢复出实体及关系的表示。与张量分解模型类似，HolE 可以获得大量的实体交互来学习潜在关系，而且有效减少了训练参数，提高了训练效率。

基于图特征模型的方法从知识图谱中观察到的三元组的边的特征来预测一条可能的边的存在。典型的方法有基于基于归纳逻辑程序（ILP）的方法，基于关联规则挖掘（ARM）的方法和路径排序（path ranking）的方法。基于 ILP 的方法和基于 ARM 的方法的共同之处在于通过挖掘的方法从知识图谱中抽取一些规则，然后把这些规则应用到知识图谱上，推出新的关系。而路径排序方法则是根据两个实体间连通路径作为特征来判断两个实体是否属于某个关系。

### **类型推理（typeinference）方法**



知识图谱上的类型推理目的是学习知识图谱中的实例和概念之间的属于关系。SDT利用三元组主语或谓语所连接属性的统计分布以预测实例的类型。该方法可以用在任意单数据源的知识图谱，但是无法做到跨数据集的类型推理。Tipalo与LHD均使用 DBpedia 中特有的 abstract 数据，利用特定模式进行实例类型的抽取。此类方法依赖于特定结构的文本数据，无法扩展到其他知识库。

![img](https:////upload-images.jianshu.io/upload_images/3455530-3013b876fea33a58.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/600)



### **模式归纳（schemainduction）方法**



模式归纳方法学习概念之间的关系，主要有基于 ILP 的方法和基于 ARM 的方法。ILP 结合了机器学习和逻辑编程技术，使得人们可以从实例和背景知识中获得逻辑结论。Lehmann 等在中提出用向下精化算子学习描述逻辑的概念定义公理的方法，即从最一般的概念（即顶概念）开始，采用启发式搜索方法使该概念不断特殊化，最终得到概念的定义。为了处理像 DBpedia 这样大规模的语义数据，该方法在中得到进一步的扩展。这些方法都在 DL-Learner中得以实现。Völker 等人在中介绍了从知识图谱中生成概念关系的统计方法，该方法通过 SPARQL 查询来获取信息，用以构建事务表。然后使用 ARM 技术从事务表中挖掘出一些相关联的概念关系。在他们的后续工作中，使用负关联规则挖掘技术学习不交概念关系，并在文献中给出了丰富的试验结果。

## **2 开放知识图谱**



本节首先介绍当前世界范围内知名的高质量大规模开放知识图谱，包括 DBpedia、Yago、Wikidata、BabelNet、ConceptNet以及Microsoft Concept Graph等，中文开放知识图谱平台 OpenKG。

### **2.1 开放知识图谱**



DBpedia 是一个大规模的多语言百科知识图谱，可视为是维基百科的结构化版本。DBpedia 使用固定的模式对维基百科中的实体信息进行抽取，包括 abstract、infobox、category 和 page link 等信息。图 2 示例了如何将维基百科中的实体“Busan”的 infobox 信息转换成 RDF 三元组。DBpedia 目前拥有 127 种语言的超过两千八百万个实体与数亿个 RDF 三元组，并且作为链接数据的核心，与许多其他数据集均存在实体映射关系。而根据抽样评测[96]，DBpedia 中 RDF 三元组的正确率达 88%。DBpedia 支持数据集的完全下载。

### **2.2 中文开放知识图谱联盟介绍**



中文开放知识图谱联盟（OpenKG）旨在推动中文知识图谱的开放与互联，推动知识图谱技术在中国的普及与应用，为中国人工智能的发展以及创新创业做出贡献。联盟已经搭建有 OpenKG.CN 技术平台，如图 5 所示，目前已有 35 家机构入驻。吸引了国内最著名知识图谱资源的加入，如 Zhishi.me， CN-DBPedia, PKUBase。并已经包含了来自于常识、医疗、金融、城市、出行等 15 个类目的开放知识图谱。

![img](https:////upload-images.jianshu.io/upload_images/3455530-d94b1e81b2ac18ba.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/558)



## 知识图谱15条军规：

1） 知识提取是投入很大的工作。因为周期长，反而更需要任务分解，化长期工作为若干可以短期交付的工作。

2）交付很重要。交付不一定要是最终的产品，尽可能思考是否可以可以把中间阶段变成可用的。按周为单位交付。

3）越是长期的工程，越需要在团队沟通上下功夫。及时通知团队成员已可交付模块的变化。

4）保持一个交付的心态。不仅对外交付，对内部也要交付。 联调系统就是交付的检查器。

5）保持工作不发霉最好的办法是晒。越是长期的工作，越要有意识地经常拿出来晒。

6）在线 Demo 是低成本沟通的好办法。

7）可视化工作的进度，并让所有的人都看到。

8）保存提取的中间产物：原始文件，富文本格式，text格式，段落篇章，Meme 提取，实体，标签……

9）不要用 RDF，或者三元组。那会带来演进的噩梦

10）保持提取出来的数据的可读性。保持合理的粒度的组织，不要分得太细，但也不要太大。如果原始数据可读性不好，多做一些自己用的工具来提升其可读性，如缩进、语法高亮、表格化、导出为 csv 等。数据可读性是数据debug的关键之一。

11）观察数据，不怕麻烦。知识提取是水磨功夫。牛人的能力往往就是掌握了快速观察的方法。

12）从第一分钟开始就写回归测试。写测试是节约开发时间，不是浪费时间。测试代码比提取代码还多是正常。测试提供反馈。

13）提取和测试，先写单线程，再多线程并发。写单线程的时候就考虑到数据可能会并发处理。队列方法可能简化处理架构。

14）尽可能避免问题大数据化。尽量避免分布式处理。先尽可能scale up，而后scale out。

15）适应没有标注数据、Golden standard。如果没有标准答案，可以试着用两种（或更多）不同的算法去解决同一个问题，然后比较结果是不是一致。不要等有标准答案。



作者：方弟
链接：https://www.jianshu.com/p/bd15e0f50eb9
来源：简书
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。





# 相关技术概述



【NLP笔记】知识图谱相关技术概述 - 三和厂妹的文章 - 知乎 https://zhuanlan.zhihu.com/p/153392625



## 一. 概念扫盲

### **知识图谱**：

一种靠关系和属性来表达实体的形式。这个定义非常的confuse，如”桌子是你眼前看到的那个桌子么？它其实是有四条腿支撑一个平面稳定的一个装置决定了它是桌子“， Google知识图谱的宣传语“things not strings”给出了知识图谱的精髓，即：**字符串背后隐含的对象或事物，这个对象是靠关系和属性支撑决定了这是实体是它而非别的实体**。

### **语义网络：**

语义网络和知识图谱非常相似，语义网络更侧重于描述概念与概念之间的关系，而知识图谱则更偏重于描述实体之间的关联，那这里又有问题了，实体和概念到底指什么？



### 实体

结论是：万物（概念也是）都是实体。但是在具体范围和背景下，你关注的东西就算实体。「的」这种副词算实体么？你关注这个字的时候就算。

实体比**命名实体**范围更广：**命名实体指**人名、机构名、地名以及其他所有以名称为标识的实体，更广泛的命名实体还包括数字、日期、货币、地址等等。但是实体呢？ 

维基百科中解释指**客观存在并可相互区别的事物。**

词典里的解释是**：**旧哲学中使用的一个概念，指能够独立存在的、作为万物本源的东西。唯心主义把它解释为精神，旧唯物主义把它解释为某种物质。

![img](Element.assets/v2-091fbc44a317ec3f249caff911713188_720w.jpg)

**概念：** 有的知识图谱是将概率从实体中区分了出来，做区分时：实体就是实实在在客观存在并可相互区别的事物，如微软的知识图谱，比如说 Spanish  Artists（西班牙艺术家）就是 Concepts（概念）， Picasso（毕加索）就是 Entities（实体）。

![img](Element.assets/v2-cbd0d5945b2c589bcff06558b3535716_720w.jpg)

### 本体

**本体：**本体是用于描述事物的本质的，维基百科里面对于计算机科学领域当中的本体给出的定义是这样的，即：对于特定领域真实存在的实体的类型、属性，以及它们之间的相互关系的一种定义。当将实体与概念区分开时，本体相当于一个类，而实体是一个对象，如「歌手」-「发行」-「专辑」是「歌手」「专辑」是本体，那么「周杰伦」-「发行」-「七里香」 ，「周杰伦」「七里香」就是实体，这其实是**schema** 的定义。在信息抽取中，我们一般预先用shema定义好我们要抽取哪些信息，安利一个开源本体编辑工具Protégé在大规模shema时非常方便编辑管理。

**语义网络实质：**  语义网络更侧重于描述概念与概念之间的关系，它其实算知识图谱的一个子集。如Hownet就是一个语义网络。语义网络非常的「语言学」，它的优势在于有概率语言模型难以捕捉到的语义知识，如在概率语言模型中，「身高」和「体重」的语义非常接近，因为他们出现的场景非常相似，但是在语义网络中这是两个完全不同的东西，语义网络的知识由我们的先验知识总结而来，更符合我们的直觉。

![img](Element.assets/v2-40398ee2cd8208c9a9d9fca1cc00e311_720w.jpg)

**知识图谱的意义**：

这种靠关系和属性来表达实体的形式，核心是是一个包含了**语义先验的数据库**，这种数据库的组织数据的形式是一张拓扑图，这种图的表达方式有利于我们的「区分」和「联系」和「推断」。

**知识图谱的形式化表达：**

知识图谱是由一些相互连接的实体和他们的属性构成的。表示为一个**SPO**三元组(Subject-Predicate-Object)，常用用**RDF** (Resource Description Framework) 形式化地表示这种三元关系。所有的实体都能这样表达，抽象程度可以很高，好的知识图谱能非常合适的根据场景控制粒度，所有的属性直指实质。

![img](Element.assets/v2-d412c9483bc77e942c81aaef0addfa7c_720w.jpg)

## 二. 分类 && 构建 

**【有哪几种知识图谱？**】

1. 常识知识图谱 | 领域知识图谱

- 比较在乎的 Relation 包括 isA Relation、isPropertyOf Relation

\2. 百科全书知识图谱

-  预定义一些谓词，比如说 DayOfbirth、LocatedIn、SpouseOf 

常识知识图谱，一般挖掘的是这些词之间的语义联系，是一些非常稳固的常识性先验知识，如「阿司匹林」-「消炎药」，非常在意准确性；对于百科知识图谱，一般会在意实体和实体之间的事实，如「王菲」-「妻子」-「李亚鹏」则需要经常更新；更实用的分法是：**领域知识图谱**和**百科知识图谱**，比如医疗知识图谱，药品知识图谱，这种垂直领域的知识图谱通常数据来源和应用领域都比较专业和固定，而百科知识图谱更像一个大杂烩。

【**知识图谱架构**】

**模式层：**

模式层最重要的工作概括为确定数据结构：哪些实体，实体类型，关系，关系类型，属性，属性类型，确定表示的粒度。

Schema属于模式层，用来规范KG的领域与描述对象，即**知识图谱数据结构的描述受schema规范和约束**。其实就是用来描述本体层(Ontology)。为知识图谱设计Schema相当于为其建立本体(Ontology)，标准的KG包括如下几部分，概念和实体是并列关系，

- 概念和概念层次
- 属性和属性值类型
- 关系
- 关系定义域概念集
- 关系值域概念集
- 在额外添加规则（Rules）或公理（Axioms）来表示模式层更复杂的约束关系

 更常用的图谱模式中，概念作为实体的一部分，定义更加的抽象：

- 领域
- 类型
- 主题

每个领域（Domain）有若干类型（Type），每个类型包含多个实体且和多个属性关联（Topic）。在垂直领域的知识图谱，你就只需要定义实体类型，关系类型，属性类型。

**数据层**：

数据层的水很深，技术栈很长很深，每一个点看起来都有点小众，仔细一查又有大量的分散的方法，又无法确定是否真的实践有用，非常的让人头秃。简单概况数据层的工作：

1. 「数据获取」结构化数据能否直接使用，半结构化数据如何转换，非结构化数据如何**信息抽取**。
2. 「清洗整理」单位，格式等的同义，知识缺失时其他标签填充，为缺失的属性构造抽取器，可以利用上下位等概念，或者其他机器学习深度学习方法，单源数据**属性融合，**多源数据的**知识融合**：**实体对齐**，**关系对齐，实体消岐**，**实体链接**等。

\3. 「数据库」**图数据库**的选择，存储方式的选择，索引等的设置。

\4. 「知识更新」：可以周期性更新，实体的拓展，监控热词更新，关键词搜索引擎的更新。

![img](Element.assets/v2-a95b63aeec4c48c9654e75e24eb8d16d_720w.jpg)

## 构建KG的核心技术 && 常用方法介绍

**「实体识别」**大家更常指的是NER命名实体识别，指识别文本中具有特定意义的实体，主要包括人名、地名、机构名、专有名词等，以及时间、数量、货币、比例数值等文字。但是前面定义中也讨论过了，实体远远不止命名实体。

  一般用序列标注问题来处理实体识别。传统的实体识别方法以统计模型如HMM、CRF等为主导，随着深度学习的兴起，DNN+CRF的结构非常的通用，DNN部分可以使用一些主流的特征抽取器如Bi-LSTM, Bert等，这种模型在数据不至于太糟的情况下，轻易就能有90%+的效果。

**「实体对齐**」具有不同标识实体（ID标识符）却代表真实世界中同一对象的那些实体，并将这些实体归并为一个具有全局唯一标识的实体对象添加到知识图谱中，即同一个实质不同的名字，需要将这些本质相同的东西归并。

**「成对实体对齐**」只考虑实体和各自属性，不考虑实体所在网络的结构，不考虑相似的传播，逻辑就是”相似的相似也相似“这种，而「协同对齐|集体对齐」考虑不同实体间的相互关系。其实不管是传统方法还是深度学习方法，都是在考虑相似性，「成对实体对齐」只考虑实体及其属性相似程度，「集体对齐」考虑了关系结构的相似性。比如有基于表层特征，扩展特征，网络特征等计算相似性方法。

- **传统方法基于概率模型做分类**，问题可以抽象为两个实体<匹配，不匹配>分类问题,  可以对属性通过贝叶斯加权等等，然后基于加权后属性相似性评分，基于代价优化，通过一个总体代价公式和贝叶斯公式产生一个最优化决策规则。(所有的实体一一对应计算，实体量大的时候计算两也是不可想象，但是聚类也是要一个个算啊)

![img](Element.assets/v2-a237b271efcf7ad6e2eb49f37ee0ef70_720w.jpg)

- **基于机器学习的方法**：

- - 把属性当成特征，使用SVM等传统分类或聚类方法，（但是存在需要各实体属性类型一致，所以只针对与专业领域实体强一致才具备应用这种方法条件）还有一些基于LDA，CRF等的模型 。

- **基于Embedding的方法**

- - 重点介绍Embedding的方法， Embedding的方法不止在实体对齐中常用，在做图推理时也经常被使用。

1. Trans-E[[1\]](https://zhuanlan.zhihu.com/p/153392625#ref_1) 系列

G是知识库，当中的实体和关系表达为 ![[公式]](Element.assets/equation) ，以JSE为目标函数， ![[公式]](Element.assets/equation-20200902171928745) 是实体中的关系， ![[公式]](Element.assets/equation-20200902171928818) 作为关系的负例， ![[公式]](Element.assets/equation-20200902171928768) 随机替换为 ![[公式]](Element.assets/equation-20200902171928747) 中的其他 ![[公式]](Element.assets/equation-20200902171928759) 或 ![[公式]](Element.assets/equation-20200902171928742) , 目标函数有点像SVM中的合页函数， ![[公式]](Element.assets/equation-20200902171928785) 比 ![[公式]](Element.assets/equation-20200902171928786) 小时没有损失，![[公式]](https://www.zhihu.com/equation?tex=f%28t_r%29) 比 ![[公式]](https://www.zhihu.com/equation?tex=f%27%28t_r%29) 大时损失才有效，因此目标函数的学习方向是 **有效关系的距离尽可能小，无效关系的距离尽可能大**

![img](Element.assets/v2-7d9645700d56894bd5863604d655d9be_720w.jpg)

Trans-E 的问题在于只适合处理一对一关系，对**一对多关系不友好**，如（中国科学院大学，地点，北京）和（颐和园，地点，北京），在 ![[公式]](https://www.zhihu.com/equation?tex=f%28t_r%29) 中尽可能小的目标小，两个三元组的 ![[公式]](Element.assets/equation-20200902171928834) 和 ![[公式]](Element.assets/equation-20200902171928832) 都一样时，会导致 ![[公式]](Element.assets/equation-20200902171928833) 很相近甚至相同，因为 ![[公式]](https://www.zhihu.com/equation?tex=r) 的表达是固定的一种，后续的基于transE的改进则都是在**r或者t的表达能力上做改进。**

\2. trans-H[[2\]](https://zhuanlan.zhihu.com/p/153392625#ref_2)系列

trans-H 在trans-E的基础上，通过一个超平面的映射，通过分解 ![[公式]](https://www.zhihu.com/equation?tex=r) 来增强 ![[公式]](Element.assets/equation-20200902171928833) 和 ![[公式]](Element.assets/equation-20200902171928832) 的表达能力。

![img](Element.assets/v2-0907a2f07db4bdc9e6002ecb3dfebfd9_720w.jpg)

将Trans-E中的 ![[公式]](https://www.zhihu.com/equation?tex=r) 的集合 ,替换为可以在超平面的分解法向量 ![[公式]](Element.assets/equation-20200902171928888) 和 ![[公式]](Element.assets/equation-20200902171929053) 超平面上的翻译向量组成，并且满足约束 ![[公式]](Element.assets/equation-20200902171928952) , 即在之前transE中的 ![[公式]](Element.assets/equation-20200902171928924) 关系映射到了另外一个平面，那在同样一个元素如 ![[公式]](Element.assets/equation-20200902171928924-9038368.) 在原始空间中对应着有多重表达，即**多了一层超平面的表达能力。**其他就类似transE表达：

![[公式]](Element.assets/equation-20200902171928923) 

\3. trans-R[[3\]](https://zhuanlan.zhihu.com/p/153392625#ref_3)系列 and trans-D[[4\]](https://zhuanlan.zhihu.com/p/153392625#ref_4) 系列

![img](Element.assets/v2-50d2912314ca937144d633e04473e52e_720w.jpg)

trans-R 将 ![[公式]](https://www.zhihu.com/equation?tex=r) 更复杂化成一个矩阵，先将 ![[公式]](Element.assets/equation-20200902171928833) 和 ![[公式]](Element.assets/equation-20200902171928832) 通过关系映射矩阵 ![[公式]](Element.assets/equation-20200902171929027) 映射到另一个空间 ， 相当于TransE 中通过 ![[公式]](https://www.zhihu.com/equation?tex=r) 分解 ![[公式]](https://www.zhihu.com/equation?tex=h) 和 ![[公式]](https://www.zhihu.com/equation?tex=t) , 取出 ![[公式]](https://www.zhihu.com/equation?tex=r) 的某个方面。

trans-D 在trans-R的基础上在 ![[公式]](Element.assets/equation-20200902171929027) 中加入了 ![[公式]](https://www.zhihu.com/equation?tex=h) 和 ![[公式]](https://www.zhihu.com/equation?tex=t) 项, 认为映射方式不能只由关系决定， ![[公式]](https://www.zhihu.com/equation?tex=M_r) 做映射的时候加入了 ![[公式]](Element.assets/equation-20200902171928768) 本身的语义信息，无形中相当于做了方向限制。

![[公式]](Element.assets/equation-20200902171929090)  

\4. 基于属性和结构embedding的实体对齐

![img](Element.assets/v2-f5ddb601b880e310092e2c7d5b54e7d5_720w.jpg)

基于结构和属性的相互监督的对齐[[5\]](https://zhuanlan.zhihu.com/p/153392625#ref_5)文章将目标定义为3个部分，谓词对齐，embedidng学习，实体对齐。谓词对齐用编辑距离，用0.95的阈值来卡 ，0.95应该是编辑距离数/总体字符个数。 embedidng学习的部分 ![[公式]](https://www.zhihu.com/equation?tex=J%3DJ_%7BSE%7D%2BJ_%7BCE%7D%2BJ_%7Bsim%7D) , 即在学习 ![[公式]](Element.assets/equation-20200902171928768) 的embediing的同时也要学习他们结构的关系，知识图谱也是一种图，图的结构对一个节点的表达意义巨大，最后将属性和结构相似也累加，效果不错。

![img](Element.assets/v2-8781396e510cd3b0392c7cc8f458d4c5_720w.jpg)

**评测方法**：hits@1，hits@10s，MeanRank

假设整个知识库中一共有n个实体，那么评价过程如下：

- 一个正确的三元组a中的头实体或者尾实体，依次替换为整个知识库中的所有其它实体，也就是会产生n个三元组。
- 分别对上述n个三元组计算其能量值，在transE中，就是计算h+r-t的值。这样可以得到n个能量值，分别对应上述n个三元组。
- 对上述n个能量值进行升序排序。(从小到大的排序)
- 记录三元组a的能量值排序后的序号。
- 对所有的正确的三元组重复上述过程。
- 每个正确三元组的能量值排序后的序号求平均，得到的值我们称为**MeanRank**。
- 计算正确三元组的能量排序后的序号小于10的比例，得到的值我们称为Hits@10。



**「实体消岐」**是用于解决同个实体名称在不同语句不同意义的问题，同一个词不同的实质，如apple 在知识图谱里至少有两个歧义，静态词向量无法解决这个问题，不能要求你的知识库里所有的苹果 ，都是吃的苹果。

- **实体归并到概念：**先抽象出概念，然后根据实体属性，将实体归并到这些概念中，首先**获取实体含义构成关键词词组**，如97年版《天龙八部》：[“1997”, “李添胜”, “天龙八部”, “黄日华”, “樊少皇”,"电视剧"] ，腾讯动漫的天龙八部：[“漫画作品”, “天龙八部”,  “连载”, “腾讯”, “动漫”, “凤凰”, ]。

1. **概念已知**的情况下，直接利用关键词组对实体进行**文本分类**。
2. **概念未知**时，可以从关键词组中抽取出概念，最常用的是在抽取的过程中直接利用实体的上位词，如电视剧《天龙八部》，或者在百科知识图谱中利用Info Box中的说明。
3. **实体在概念内的消岐**，如 97版天龙八部还是03内地胡军版天龙八部电视剧，这种消岐本质是选择一个层次的最典型关键词代表，可以利用Name  Dictionary（消岐词表|命名字典），命名字典包含了各种命名实体的名称的表达方式，如：变体、缩写、混淆名称、拼写变体等，命名字典的最常见的构建利用了大量类似wikipedia这种百科知识图谱中的信息。或者在Candidate Entity Generation生成候选实体后经过排序得到。在这里**实体消岐和实体链接是一致的**，具体常用方法在实体链接中说明。

- **监督学习候选实体排序方法**包括二分类、学习排序、概率方法和基于图的方法，给定<实体指称项，  候选实体>对，用二分类器去判断是否实体指称项能否链接到实体对象上，基于置信度的方法、VSM的方法等排序。一个是正负样本的极度不均衡，另一个当是多个候选实体被分为正样本，则需要使用其他的技术再去选择出最适合的候选实体。
- **非监督学习排序方法**包括基于向量空间模型的方法和基于信息检索的方法。

**「实体链接」**将自由文本中已识别的实体对象（人名、地名、机构名等），无歧义的正确的指向知识库中目标实体的过程。本质仍是同一个词不同实质，如已有一个知识库的情况下，预测输入query的某个实体对应知识库id，如 apple 在一个有上下文的query中是指能吃的apple 还是我们手上用的apple。**实体链接强调链接的过程，而消岐强调先描述这个实体是什么。**

当然有一些直接「基于实体链接的实体消歧方法」，个人觉得还是属于链接。 消岐和链接这个概念还是常常在被混淆，方法很多也通用，以致于也不知道到底谁标准。

实体消歧时，不同场景的特征选取是非常重要的，基于上下文消岐和上下文独立非常不一样。比如做百科问答或是通用文本的阅读增强，就很依赖于**wikipedia和搜索引擎，**但如果是某个具体的行业领域，就需要通过一些**启发式的方法、用户日志、网页爬取，甚至人工标注的方法**来构建Name Dictionary。这里的Name Dictionary命名字典在构建时需要的一些消岐处理（上文提过那个），然后应用于实体链接。

1. 下文独立：

- LinkCount：(m->e)，知识库中某个提及m指向实体e的次数；
- Entity Attributes：Popularity、Type；

LinkCount常常可以用该实体在文本中出现的频次表达，**作为一个先验知识，在消歧时，这很有用**，比如当我们在问“姚明有多高？”时，大概率都是在问<篮球运动员姚明>，而不是其他不为人知的“姚明”。虽然context中完全没有包含篮球运动员这一信息，但大多数情况下，根据“姚明”到<篮球运动员姚明>的LinkCount最高，选其作为实体进行查询。 另外可以用一般指实体自身的一些属性（比如热度、类型、所在实体的篇章属性等等）来做链接。

\2. 上下文不独立：

- - Textual Context：BOW,  Concept Vector
  - Coherence Between Entities：WLM、PMI、Jaccard Distance

文本上下文可以用一些深度学习的方法去深度理解文本的语义，从而实现消歧；实体间的一致性则可以用一些文本相似性来计算。对于监督方法，可以当成二分类问题处理，给定<实体指称项， 候选实体>对，用二分类器去判断是否实体指称项能否链接到实体对象上。输出是对每一对<实体指称项，  候选实体>的标签判断，可以使用一下三种类型方法：

- **基于搜索排序的方法：**Point-wise，Pair-wise，List-wise。Point-wise、Pair-wise、List-wise分别代表搜索排序中，一个query对应一个truth, 两个truth，多个truth。 由于ED任务ground  truth只有一个实体，一般都是用point-wise来做。输入是文本的context、mention、某个entity的一些attributes，输出mention指向该entity的置信度，以此rank，选出最可信的entity。
- **基于概率模型：**结合不同信息，得到条件概率P(e|m,c)P(e|m,c)，其中 c 是输入文本，e 为实体， m 是mention。比如用归一化的LinkCount信息，作为先验概率P(e|m)P(e|m)。
- **基于图的模型**：利用图特征 (entity embedding、relation)，在消歧时，考虑全局消歧后实体的一致性。

一般可能会同时基于以上三种方法来做，在CCKS的冠军训练方案[[6\]](https://zhuanlan.zhihu.com/p/153392625#ref_6)中，在已知候选项的时候（候选项在实体消岐的时候已经全部得到），链接就是一个分类问题，将mention与候选项拼接直接深度学习一把梭做二分类，效果出奇。

【**信息抽取**】当信息来源是非结构化文本时，构建知识图谱关键的一步是需要从非结构化文本中抽取去结构化信息。知识图谱中的信息抽取是从自然语言文本中抽取指定类型的实体、关系、事件等事实信息，并形成结构化数据输出的文本处理技术。在知识图谱构建所需的RDD三元组结构中，一般抽取的信息也是「实体」-「关系」-「实体」，知识图谱的构建会先确定好要抽取的信息，确定抽取信息的schema, 然后基于schema去抽取信息。

- Pipeline：把**实体识别**和**关系分类**作为两个完全独立的过程，不会相互影响，关系的识别依赖于实体识别的效果。
- Joint  Model：实体识别和关系分类的过程共同优化。

采用pipline方法时，基于schema的信息抽取任务分解为NER+ 关系分类，实践中大多数也是这样做的，但是pipline却分割了两个任务之间的连接关系，特别是有一些从属和并列关系，指代问题，省略等，导致需要想另一些方法去将任务直接的结果对应起来。

Joint Model 任务一般会在模型的输入将所需特征做一些组合，在输出端做一些多输出的改造同时得到多个输出结果，这种多任务改造避免的pipline分割了模型结果的问题，但多任务模型同时也有一些固有的弊端。在[[7\]](https://zhuanlan.zhihu.com/p/153392625#ref_7)中，对输出做一些改造避免了pipline的一些重叠与对应问题。

【**知识图谱融合**】知识图谱的融合的核心是**实体对齐**和**schema融合**以及解决**数据冲突**，实体对齐前面已经提到过，本体匹配侧重发现模式层等价或相似的类、属性或关系，也成为本体映射（mapping）、本体对齐（alignment）。

Schema mapping的难点是**属性体系并非简单的一对一关系:**

- 出生={出生日期，出生地点} 
- 出生日期={出生年份，出生月，出生日} 

**需要综合利用多种类别的信息 ：**

属性的语义信息 

- 成立={创立，建立} 
- 出生={诞辰，诞生} 

属性的值分布信息 

- 出生日期的主要值为时间 
- 总部的主要值为机构 

 属性的联合分布 

- 出生日期+出生地点+职业+单位 =>人

**Schema之间的蕴含关系：**

- 公司.创始人 => 公司.员工 
- 收购（公司，公司）=>合开（公司，公司）

可以建立一个全局的Schema， 利用一个Base learner，将不同知识源中 的schema到全局Schema进行映射 ， 使用Meta-Learner来综合利用Base learner的分类结果并利用属性的联合分布信息，从而得到最 终的Schema mapping全局结果。

**知识融合**一般通过冲突检测、真值发现等技术消解知识图谱融合过程中的冲突，再对知识进行关联与合并，最终形成一个一致的结果，知识图谱构建不是一个静态的过程, 需要 及时更新动态知识 。加入新知识 需要判断新知识是否是否正确，不已有知识 是否一致。

解决知识冲突可以从几个方面选择，权威度高的信息源更有可能出现正确的答案 ； 有冲突知识时正确的答案更有可能出现 的次数更多；实际应用中大家可以参考[[8\]](https://zhuanlan.zhihu.com/p/153392625#ref_8)。

**「知识图谱推理」**：推理是知识图谱的核心，先推荐一个非常棒的课程[[9\]](https://zhuanlan.zhihu.com/p/153392625#ref_9)，下面简单总结方法

1. **基于符号逻辑的推理——本体推理**

- 传统的符号逻辑推理中主要是基于描述逻辑的本体推理。描述逻辑主要被⽤来对事物的本体进⾏建模和推理，⽤来描述和推断概念分类及其概念之间的关系。

- 主要方法：

- - 基于表运算（Tableaux）及改进的⽅法：FaCT++、 Racer、  Pellet Hermit等；
  - 基于Datalog转换的⽅法如KAON、RDFox等；
  - 基于产⽣式规则的算法（如rete）：  Jena 、 Sesame、OWLIM等；

- RDF表示关系层次受限，因此有了RDFS，在RDF的基础上，新增了Class,  subClassOf, type, Property, subPropertyOf, Domain, Range 词汇，可以更好的表述相关关系

这种逻辑符号推理也叫OWL为本体语言，OWL是知识图谱语言中最规范最严谨， 表达能力最强的语言[[9\]](https://zhuanlan.zhihu.com/p/153392625#ref_9)，基于RDF语法，使表示出来的文档具有语义理解的结构基础，促进了统一词汇表的使用，定义了丰富的语义词汇，且允许逻辑推理。

![img](Element.assets/v2-a28540d00a111447b86109747ac1703f_720w.jpg)

**2. 基于图结构和统计规则挖掘的推理**

- 基于路径排序学习⽅法(PRA， Path ranking Algorithm)
- 基于关联规则挖掘⽅法(AMIE)

即将连接两个实体的路径作为特征来预测其间可能存在的关系

![img](Element.assets/v2-2d2cafab8ef1c4a1b4db4d3728edece7_720w.jpg)

路径排序算法 Path Ranking Algorithm (PRA)

![img](Element.assets/v2-cacc91b5c606928448396aed25cfeedb_720w.jpg)

**3. 基于知识图谱表示学习的关系推理**

- 将实体和关系都表示为向量
- 通过向量之间的计算代替图的遍历和搜索来预测三元组的存在，由于向量的表示已经包含了实体原有的语义信息，计算含有⼀定的推理能⼒。
- 可应⽤于链接预测，基于路径的多度查询等
- transE

\4. **基于概率逻辑的⽅法——Statistical Relational Learning**

- 概率逻辑学习有时也叫Relational Machine Learning (RML)，关注关系的不确定性和复杂性。通常使用Bayesian networks or Markov networks

【**应用场景**】

1. **知识图谱问答**，之前写过一点具体参考[[10\]](https://zhuanlan.zhihu.com/p/153392625#ref_10)

**2. 个性化推荐：**通过实体与实体之间的关系，利用用户感兴趣的实体，进一步扩展用户偏好的相似的实体，提供可解释性的推荐内容。一方面，图谱提供了实体在多个维度的特征信息，另一方面，表示学习向量带有一定的语义信息，使得寻找推荐实体更接近目标实体或更偏向用户喜好。

**3. 语义搜索**，搜索引擎对Query的处理不再拘泥于字面本身，而是抽象出其中的实体、查询意图，通过知识图谱直接提供用户需要的答案，而不只是提供网页排序结果，更精准的满足用户的需求。当前Google、百度、神马搜索都已经将基于知识图谱的语义搜索融入到搜索引擎中，对于一些知识性内容的查找，能智能地直接显示结果信息。

**4. 金融风险管理和反欺诈**：知识图谱中的社区发现、标签传播等方法来对用户进行风险管理，能够更准确的识别逾期客户以及用户的不良行为，从而大大提升信用风险管理能力。团伙通常会存在较多关联及相似特性，图谱中的关系可以帮助人工识别出多层、多维度关联的欺诈团伙，再利用规则等方式，识别出批量具有相似行为的客户，辅助人工优化调查，同时可以优化策略。

\5. **图像视频理解：**实现视频的深度语义理解，在纯感知技术的基础上，利用知识图谱进行深度语义理解，这样识别出的结果没有刻画出用户对视频核心的细粒度兴趣，比如影视剧的角色、关系等知识，利用知识图谱对视频做深度结构化的解析，然后上层的推荐、搜索可以应用这些知识作为特征辅助内容的高效分发[[11\]](https://zhuanlan.zhihu.com/p/153392625#ref_11)。

## 参考

1. [^](https://zhuanlan.zhihu.com/p/153392625#ref_1_0)Translating Embeddings for Modeling Multi-relational Data（
2. [^](https://zhuanlan.zhihu.com/p/153392625#ref_2_0)Knowledge Graph Embedding by Translating on Hyperplanes
3. [^](https://zhuanlan.zhihu.com/p/153392625#ref_3_0)Learning Entity and Relation Embeddings for Knowledge Graph Completion
4. [^](https://zhuanlan.zhihu.com/p/153392625#ref_4_0)Knowledge Graph Embedding via Dynamic Mapping Matrix
5. [^](https://zhuanlan.zhihu.com/p/153392625#ref_5_0)Entity Alignment between Knowledge Graphs Using Attribute Embeddings
6. [^](https://zhuanlan.zhihu.com/p/153392625#ref_6_0)https://github.com/panchunguang/ccks_baidu_entity_link
7. [^](https://zhuanlan.zhihu.com/p/153392625#ref_7_0)https://spaces.ac.cn/archives/6671
8. [^](https://zhuanlan.zhihu.com/p/153392625#ref_8_0)http://bj.bcebos.com/cips-upload/kg/cips.pdf
9. ^[a](https://zhuanlan.zhihu.com/p/153392625#ref_9_0)[b](https://zhuanlan.zhihu.com/p/153392625#ref_9_1)https://github.com/npubird/KnowledgeGraphCourse
10. [^](https://zhuanlan.zhihu.com/p/153392625#ref_10_0)https://zhuanlan.zhihu.com/p/150119544
11. [^](https://zhuanlan.zhihu.com/p/153392625#ref_11_0)https://zhuanlan.zhihu.com/p/122373439

# 00从知识工程到图谱全面回顾

- 
- 数智物语的文章 - 知乎 https://zhuanlan.zhihu.com/p/67914830



> 像人一样的思考能力具体体现在：机器对数据和语言的理解、推理、解释、归纳、演绎的能力，体现在一切人类所独有的认知能力上。学界业界都希望通过计算机模拟，让机器获得和人类相似的智慧，解决智能时代下的精准分析、智慧搜索、自然人机交互、深层关系推理等实际问题。
>
> 
>
> 知道了认知智能是机器智能化的关键，进一步我们要思考，如何实现认知智能——**如何让机器拥有理解和解释的认知能力。**







知识工程主要包括：知识获取、知识表示和知识应用。我们可以尝试突破的方向在于知识的利用，在于对符号知识和数值模型结合的应用。而这些努力，最终结果就是使机器具备理解和解释的能力。





**01知识工程前世今生**



## 01知识工程起源



### **20世纪50年代—70年代初**【符号主义

**知识工程诞生之前的早期人工智能**



那么知识图谱到底将如何助力人工智能？回顾历史总能帮助我们更好的理解未来。把时间的车轮回滚到 1956 年 8 月，在美国汉诺斯小镇宁静的达特茅斯学院中，几位心理学家、数学家、计算机科学家、信息论学家聚在一起，举办了一次长达 2  个月的研讨会，认真而热烈地讨论了用机器模拟人类智能的问题。他们为会议的内容起了一个响亮的名字：人工智能(artificial  intelligence)。



人工智能学科自此诞生。





![img](Element.assets/v2-48ce46a3a90f8f4fda91414aaeb5bde2_720w.jpg)



传统知识工程代表性人物与成就



达特茅斯会议之后，参会者们相继取得了一批令人瞩目的研究成果。具有代表性的成果为：A.Newell、J.Shaw 和 H.Simon 等人编制出逻辑机 LT，它证明了 38 条数学定理；1960 年又定义了 GPS  的逻辑推理架构，并且提出启发式搜索的思路；1956 年， Samuel  研制了一个跳棋程序，该程序具有自学习功能，可以从比赛中不断总结经验提高棋艺。还有很多令人激动的成就，这掀起人工智能发展的第一个高潮。





![img](Element.assets/v2-e294c125ce97ef61c1af179bed8d96d4_720w.jpg)





其中，以 Newell 和 Simon 为代表人物的符号主义学派，最先取得丰硕成果，最著名的代表为逻辑机 LT。



符号主义最核心的思想是什么呢？**符号主义认为人工智能源于数理逻辑，认为智能的本质就是符号的操作和运算。**符号主义在后来几大门派的较量中，曾长期一支独秀，为人工智能的发展作出重要贡献。当然，也为后来红火一时的知识工程奠定了基业。



再把时间的焦点挪到 20 世纪 60 年代— 70 年代初，学界还在为人工智能发展初期取得的胜利高兴不已的时候，不切实际的研发目标带来接二连三的项目失败、期望落空。过高的期望总是带来更具破坏性的失望，终于，人工智能迎来第一次寒冷的冬天。









### **1977 专家系统**

**知识工程诞生**



在人工智能领域经历挫折之后，研究者们不得不冷静下来，重新审视、思考未来的道路。这时候，西蒙的学生，爱德华·费根鲍姆(Edward A. Feigenbaum)站了出来。他分析传统的人工智能忽略了具体的知识，人工智能必须引进知识。





![img](Element.assets/v2-fab73eed1fb16c7e875bc82c46938d87_720w.jpg)



爱德华·费根鲍姆(Edward Feigenbaum，1936-)，美国计算机科学家，专家系统之父，知识工程奠基人，曾获得 1994 年图灵奖。他有一句名言流传甚广：“Knowledge is the power in AI”。



在费根鲍姆的带领下，专家系统诞生了。**专家系统作为早期人工智能的重要分支，是一种在特定领域内具有专家水平解决问题能力的程序系统。**

##### **两部分组成：知识库与推理引擎**

**专家系统一般由两部分组成：知识库与推理引擎。**它根据一个或者多个专家提供的知识和经验，通过模拟专家的思维过程，进行主动推理和判断，解决问题。第一个成功的专家系统 DENDRAL 于 1968 年问世。1977 年，费根鲍姆将其正式命名为知识工程。



把知识融合在机器中，让机器能够利用我们人类知识、专家知识解决问题，这就是知识工程要做的事。





### 1998语义网链接

**万维网与连接数据**



万维网的出现，为知识的获取提供了极大的方便。1998 年，万维网之父蒂姆·伯纳斯·李再次提出语义网。它的核心是：语义网可以直接向机器提供能用于程序处理的知识。**通过将万维网上的文档转化为计算机所能理解的语义，使互联网成为信息交换媒介。**但是，语义网是一个比较宏观的设想，需要“自顶向下”的设计，很难落地。





传统知识工程为什么会有这么苛刻的条件呢？**因为传统知识工程是一种典型的自上而下的做法，是一种严重依赖专家干预的做法。**知识工程的基本目标，就是把专家的知识赋予机器，希望机器能够利用专家知识来解决问题。传统的知识工程里，首先需要有领域专家，专家能够把自己的知识表达出来；进一步，还需要有知识工程师把专家表达这个知识变成计算机能够处理的形式。





### 传统的知识工程面临着的两个主要困难：



- **第一：知识获取困难**
  隐性知识、过程知识等难以表达。比如如何表达老中医看病用了哪些知识；不同专家可能存在主观性，例如，我国有明确治疗规范的疾病占比非常小，大部分依赖医生的主观性。
- **第二：知识应用困难**
  很多的应用，尤其是很多开放性的应用很容易超出预先设定的知识边界；还有很多应用需要常识的支撑，**而整个人工智能最怕的恰恰就是常识。**为什么？因为常识它难以定义、难以表达、难以表征；知识更新困难，太依赖领域专家，还有很多异常或难以处理的情况。







## **02知识图谱引领知识工程复兴**



大数据时代下知识图谱的出现，有其必然性，大数据时代给知识图谱技术的发展奠定了丰富的土壤。或许你会问，知识图谱和传统的语义网络有什么本质不同么？大数据时代能给我们带来什么特别的有利条件？前沿进展的回答是——



**大数据技术使得大规模获取知识成为可能，而知识图谱即为一种大规模语义网络。这样的一个知识规模上的量变带来了知识效用的质变。**



我们有海量的数据、强大计算能力、群智计算以及层出不穷的模型。在这些的外力的支持下，解决了传统知识工程的一个瓶颈性问题——**知识获取**。我们可以利用算法实现数据驱动的大规模自动化知识获取。





### 符号主义声势渐长



以知识图谱为代表的符号主义声势渐长，这个蕴含大量先验知识的宝箱正被大数据技术开启。 | ©ontotext

##### 利用数据**自下而上**

和传统知识获取不同，以前是通过专家自上而下的获取知识，而现在是利用数据**自下而上**，

从数据里面去挖掘知识、抽取知识。另外，**众包与群智**成为大规模知识获取的一条新路径。

高质量的 UGC 内容，为自动挖掘知识提供了高质量数据源。



总的来说，知识工程在知识图谱技术引领下进入了全新阶段，叫做大数据时代知识工程阶段。肖仰华教授提出了一个简单的公式表明传统知识工程与以知识图谱为代表的新一代知识工程的联系与区别：



**Small knowledge + Big data=Big knowledge**



大数据知识这个词是 BigKE，它将会显著提升机器认知智能水平，那么，大数据知识工程对我们人工智能最根本的意义是什么？是提升机器的认知智能水平。我们正在经历感知智能到认知智能的过渡阶段，未来最重要到技术即是实现认知智能。

### 知识图谱又有什么独特的魅力

大数据时代下，知识图谱又有什么独特的魅力？为什么会受到如此广泛的关注呢？



##### **知识图谱使机器语言认知成为可能。**

机器想要认知语言、理解语言，需要背景知识的支持。而知识图谱富含大量的实体及概念间的关系，可以作为背景知识来支撑机器理解自然语言。



##### **知识图谱使可解释人工智能成为可能。**

在人工智能发展的任何阶段，我们都需要事物的可解释性，现在的深度学习也常因为缺少可解释性受人诟病。而知识图谱中包含的概念、属性、关系是天然可拿来做解释的。 





![img](Element.assets/v2-4ee7acb491da17defe3c034ec60dd2dc_720w.jpg)



通过知识图谱等先验的知识去赋能机器学习，来降低机器学习对于样本的依赖，增强机器学习的能力。



知识将显著增强机器学习能力。传统的机器学习都是通过大量的样本习得知识，在大数据红利渐渐消失的情况下，逐渐遇到发展瓶颈。**而通过知识图谱等先验的知识去赋能机器学习，来降低机器学习对于样本的依赖，增强机器学习的能力，或许是连接主义和符号主义在新时代下的共生发展。**



除了上述的种种优势，知识图谱在一系列实际应用上也非常有用，比如搜索、精准推荐、风险识别、深化行业数据的理解与洞察等，将在各种各样的应用场景发挥作用。



信息技术革命持续进行，数据将会继续向更大规模、更多连接的方向发展，在此背景下，知识图谱将引领知识工程走上复兴的道路，推动在机器身上实现认知智能。





# END