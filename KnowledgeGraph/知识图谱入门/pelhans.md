

# 知识图谱入门

#  (一)  知识图谱与语义技术概览



欢迎大家关注我的博客 [http://pelhans.com/](https://link.zhihu.com/?target=http%3A//pelhans.com/) ，所有文章都会第一时间发布在那里哦~

------

> 知识图谱与语义技术概览。主要介绍知识表示、知识抽取、知识存储、知识融合、知识推理、知识众包、语义搜索、知识问答等内容。同时还包含一些典型的应用案例。本系列笔记为王昊奋老师知识图谱课程的学习笔记，若理解有偏差还请指正。课程购买连接在文末。

## 知识图谱与语义技术概览

## 知识图谱的概念演化

​       知识图谱(Knowledge Graph， KG)的概念演化可以用下面这幅图来概括:

![img](pelhans.assets/v2-932cd80e66238f5b8ebc59dc2277e373_720w.jpg)

​       在1960年，语义网络(Semantic  Networks)作为知识表示的一种方法被提出，主要用于自言语言理解领域。它是一种用图来表示知识的结构化方式。在一个语义网络中，信息被表达为一组结点，结点通过一组带标记的有向直线彼此相连，用于表示结点间的关系。如下图所示。简而言之，语义网络可以比较容易地让我们理解语义和语义关系。其表达形式简单直白，符合自然。然而，由于缺少标准，其比较难应用于实践。

![img](pelhans.assets/v2-93b8c41eab14907f359ae799920bbda5_720w.jpg)

​        1980s出现了本体论(Ontology)，该本体是由哲学概念引入到人工智能领域的，用来刻画知识。在1989年Time Berners-Lee发明了万维网，实现了文本间的链接。

​        1998年语义网(THe Semantic  Web)被提出，它从超文本链接到语义链接。语义网是一个更官方的名称，也是该领域学者使用得最多的一个术语，同时，也用于指代其相关的技术标准。在万维网诞生之初，网络上的内容只是人类可读，而计算机无法理解和处理。比如，我们浏览一个网页，我们能够轻松理解网页上面的内容，而计算机只知道这是一个网页。网页里面有图片，有链接，但是计算机并不知道图片是关于什么的，也不清楚链接指向的页面和当前页面有何关系。语义网正是为了使得网络上的数据变得机器可读而提出的一个通用框架。“Semantic”就是用更丰富的方式来表达数据背后的含义，让机器能够理解数据。“Web”则是希望这些数据相互链接，组成一个庞大的信息网络，正如互联网中相互链接的网页，只不过基本单位变为粒度更小的数据，如下图。

![img](pelhans.assets/v2-e0a0eaeffa6cbc81240ffa97781a337c_720w.jpg)

​        2006年Tim突出强调语义网的本质是要建立开放数据之间的链接，即链接数据(LInked  Data)。2012年谷歌发布了其基于知识图谱的搜索引擎产品。可以看出，知识图谱的提出得益于Web的发展和数据层面的丰富，有着来源于知识表示(Knowledge Represention， KR)、自然语言处理(NLP)、Web、AI多个方面的基因。可用于搜索、问答、决策、AI推理等方面。

## 知识图谱的本质

​        知识图谱目前没有标准的定义，这里引用一下“Exploiting Linked Data and Knowledge Graphs in Large Organisations”这本书对于知识图谱的定义：

> A knowledge graph consists of a set of interconnected typed entities and their attributes.

​        即**知识图谱是由一些相互连接的实体和它们的属性构成的**。最简单情况下它长这样：

![img](pelhans.assets/v2-791b5fc49fab78215b26af8ad5f2022f_720w.jpg)

复杂一些是这样的：

![img](pelhans.assets/v2-cc8a742560d1c316377df3f180f4b10c_720w.jpg)

​         前面说过，知识图谱综合了众多方面，其中从Web角度看KG，它像建立文本之间的超链接一样，建立数据之间的语义链接，并支持语义搜索。从NLP角度看，它主要在做怎么能够从文本中抽取语义和结构化的数据。从知识表示角度看是怎么利用计算机符号来表示和处理知识。从AI角度则是怎么利用知识库来辅助理解人类的语言。从数据库角度看就是用图的方式存储知识。因此要做好KG要综合利用好KR、NLP、Web、ML、DB等多方面的方法和技术。

## 知识图谱技术概览

![img](pelhans.assets/v2-b31060b4a7607a452c7ead003c42a660_720w.jpg)

​         上图表示了知识图谱的技术体系，首先在最底层我们有大量的文本、结构化数据库、多媒体文件等数据来源。通过知识抽取、知识融合、知识众包等技术，获取我们需要的数据，而后通过知识表示和知识推理、知识链接等将知识规范有序的组织在一起并存储起来。最终用于知识问答、语义搜索、可视化等方面。

## 知识表示

​        知识表示研究怎么利用计算机符号来表示人脑中的知识，以及怎么通过符号之间的运算来模拟人脑的推理过程。

![img](pelhans.assets/v2-9662e808f7a69ab388a624c5fca429ca_720w.jpg)

​        上图给出了知识表示的演化过程，其中最主要根本的变化是从基于数理逻辑的知识表示过渡到基于向量空间学习的分布式知识表示。

下图给出官方推荐的语义网知识表示框架：

![img](pelhans.assets/v2-475478e95b3c025138f9471a6d8223c6_720w.jpg)

​         其中最底层的是URI/IRI是网络链接，其上是XML和RDF为资源表示框架。SPARQL是知识查询语言。被蓝色部分覆盖的是推理模块，它包含了如RDFS和OWL这样的支持推理的表示框架。在往上就是trust和interaction部分，暂时不需要了解(还不清楚是什么，只知道用不到。。。)。

## RDF

​        RDF(Resource Description  Framework)即资源描述框架，是W3C制定的。用于描述实体/资源的标准数据模型。在知识图谱中，我们用RDF形式化地表示三元关系。(Subject, predicate, object)。例如:

![img](pelhans.assets/v2-60fea0a71a2ab9bea421babc2df95481_720w.jpg)

​        RDFS在RDF的基础上定义了一些固定的关键词如：Class，subClassOf，type， Property， subPropertyOf， Domain， Range以及多了Schema层。它的表示为：

![img](pelhans.assets/v2-fa39bfc04cdaef93a7d01784a3686738_720w.jpg)

## OWL

​        OWL(Web Ontology Language), 这个本体就是从哲学那面借鉴来的。OWL在RDF的基础上扩充了Schema层，使它支持推理等操作。如：

![img](pelhans.assets/v2-138aa962da30f388a46d340c19d0f3e1_720w.jpg)

## SPARQL

​         SPARQL是RDF的查询语言，它基于RDF数据模型，可以对不同的数据集撰写复杂的连接，由所有主流的图数据库支持。其操作如：

![img](pelhans.assets/v2-9088330138d80b0f593363436fd9de21_720w.jpg)

## JSON-LD

​        JSON for Linking Data: 适用于作为程序之间做数据交换,在网页中嵌入语义数据和Restful Web Service。存储格式如:

![img](pelhans.assets/v2-710eb8efa01bfadb8bf7bce641006acb_720w.jpg)

## 知识图谱的分布式表示--KG Embedding

​        其实看到 Embedding这个词我们就知道，它是一个向量嵌入。详细来说就是在保留语义的同时，将知识图谱中的实体和关系映射到连续的稠密的低维向量空间。

![img](pelhans.assets/v2-f7911ff9459d22da755e097aed5963f9_720w.jpg)

## 知识抽取

​        知识抽取是一个结合NLP和KR的工作，它的目标是抽取KR用的三元组、多元关系、模态知识等。具体流程如下：

![img](pelhans.assets/v2-3543bc77893f543466e91b17b7321a3f_720w.jpg)

​         文字表述为，首先从网络上获取大量的各种非结构化的文本数据，经过文本预处理后得到干净的文本数据。而后借助机器学习相关程序对文本进行分词、词性标注、词法解析、依存分析等工作，此时词法及句法层次的分析结束，接下来对该文本进行NER和实体链接工作，为关系抽取和时间抽取做准备，最终形成KR用的三元组、多元关系、模态知识等构成知识图谱。

## 知识问答

​        知识问答(Knowledge-Based Question Answering，  KBQA)是基于知识库的问题回答，它以直接而准确的方式回答用户自然语言提问的自动问答系统，它将构成下一代搜索引擎的基本形态。如搜索姚明的身高，就可以给出226cm的回答。其实现流程为：

![img](pelhans.assets/v2-feaa80db3e4723e62ad135f4104d9962_720w.jpg)

## 知识推理

​       简单而言，推理就是指基于已知事实推出未知的事实的计算过程，例如回答张三儿子的爸爸是谁？按照解决方法分类可分为：基于描述逻辑的推理、基于规则挖掘的推理、基于概率逻辑的推理、基于表示学习与神经网络的推理。按照推理类型分类可分为：缺省推理、连续变化推理、空间推理、因果关系推理等等。

## 知识融合

​        实体融合(Knowledge Fusion),也叫数据连接(Data  Linking)等，目的是在不同的数据集中找出一个实体的描述记录，主要目的是对不同的数据源中的实体进行整合，形成更加全面的实体信息。典型的工具为Dedupe(一个基于python的工具包)和LIMES。

## 知识众包

​        允许各网站基于一定的方式如RDFa、JASON-LD等方式在网页和邮件等数据源中嵌入语义化数据，让个人和企业定制自己的知识图谱信息。

## Ref

[王昊奋知识图谱教程](https://link.zhihu.com/?target=http%3A//www.chinahadoop.cn/course/1048)









#   (二)  知识表示与知识建模

欢迎大家关注我的博客 [http://pelhans.com/](https://link.zhihu.com/?target=http%3A//pelhans.com/) ，所有文章都会第一时间发布在那里哦~

------

> 本讲首先对早期的知识表示做了一个简单介绍，而后详细介绍了基于语义网的知识表示框架，如RDF和RDFS和查询语言SQARQL。最终给出几个典型的知识项目的知识表示。本系列笔记为王昊奋老师知识图谱课程的学习笔记，若理解有偏差还请指正。课程购买连接在文末。

## 知识表示历史

## 知识的概念

​        知识表示就是对知识的一种描述，或者说是对知识的一组约定，一种计算机可以接受的用于描述知识的数据结构。它是机器通往智能的基础，使得机器可以像人一样运用知识。

​         知识具有相对正确性、不确定性、可表示性以及可利用性的特点。根据不同划分标准，知识可以分为不同的类别。例如按照作用范围分类，可分为常识性知识和领域性知识。按作用及表示分类为事实性知识、过程性知识、控制知识。按确定性分类有确定性知识，不确定性知识。按结构及表现形式可分为逻辑性知识和形象性知识。

## 早期的知识表示方法

## 一阶谓词逻辑

​        谓词逻辑(Lp)可以对原子命题做进一步分析，分析出其中的个体词、谓词、量词，研究它们的形式结构的逻辑关系、正确的推理形式和规则。

​         一阶逻辑是数理逻辑的基础部分，主要包括经典命题逻辑和一阶谓词逻辑，但实际上一阶谓词逻辑包含了命题逻辑。一阶逻辑之所以是“一阶”的，是因为它所包含的谓词逻辑是一阶的。谓词就是表示对象属性的语词。对象的属性具有层次，在谓词用法中，这种层次叫做“阶”。所谓一阶谓词就是指刻画个体属性的谓词，如“红色”“大于”等谓词都只适用于个体概念，像“鲜艳”“传递性”等用来刻画“红色”“大于”这种谓词的谓词就是高阶谓词了，它们刻画的是属性的属性。

​        一阶谓词逻辑具有自然性、接近自然语言、容易接受、严密性、易于转化为计算机内部形式等优点，但同时也具有无法表示不确定性知识、难以表示启发性知识及元知识、组合爆炸、效率低等缺点。为了克服以上缺点，人们提出了Horn逻辑、描述逻辑等改进方案。

## 产生式系统

​         产生式系统是一种更广泛的规则系统，和谓词逻辑有关联，也有区别。早起的专家系统多数是基于产生式系统的。产生式知识表示法是常用的知识表示方式之一。它是依据人类大脑记忆模式中的各种知识之间的大量存在的因果关系，并以“IF-THEN”的形式，即产生式规则表示出来的。这种形式的规则捕获了人类求解问题的行为特征，并通过认识--行动的循环过程求解问题。一个产生是系统由规则库、综合数据库和控制机构三个基本部分组成。

​         谓词逻辑中的规则与产生式的基本形式相似,事实上,蕴涵式只是产生式的一种特殊情况。产生式规则表示法具有非常明显的优点，如自然型好，易于模块化管理、能有效表示知识、知识表示清晰等优点。但是产生式规则也有着效率不高、不能表达具有结构性的知识等缺点。因此,人们经常将它与其它知识表示方法(如框架表示法、语义网络表示法)相结合。

## 框架表示法

​        框架表示法是明斯基于1975年提出来的，其最突出的特点是善于表示结构性知识，能够把知识的内部结构关系以及知识之间的特殊关系表示出来，并把与某个实体或实体集的相关特性都集中在一起。

​        框架表示法认为人们对现实世界中各种事物的认识都是以一种类似于框架的结构存储在记忆中的。当面临一个新事物时,就从记忆中找出一个合适的框架,并根据实际情况对其细节加以修改、补充,从而形成对当前事物的认识。

​         框架是一种描述固定情况的数据结构，一般可以把框架看成是一个节点和关系组成的网络。框架的最高层次是固定的，并且它描述对于假定情况总是正确的事物，在框架的较低层次上有许多终端--被称为槽（Slots）。在槽中填入具体值，就可以得到一个描述具体事务的框架，每一个槽都可以有一些附加说明--被称为侧面（Facet），其作用是指出槽的取值范围和求值方法等。一个框架中可以包含各种信息：描述事物的信息，如何使用框架的信息，关于下一步将发生什么情况的期望及如果期望的事件没有发生应该怎么办的信息等等，这些信息包含在框架的各个槽或侧面中。

​         一个具体事物可由槽中已填入值来描述，具有不同的槽值得框架可以反映某一类事物中的各个具体事物。相关的框架链接在一起形成了一个框架系统，框架系统中由一个框架到另一个框架的转换可以表示状态的变化、推理或其它活动。不同的框架可以共享同一个槽值，这种方法可以把不同角度搜集起来的信息较好的协调起来。

![img](pelhans.assets/v2-e0555b9bb590cffe51ce074cbac1518d_720w.jpg)

​        框架表示法对于知识的描述非常完整和全面;基于框架的知识库质量非常高;且框架允许数值计算,这一点优于其它知识表示语言。但框架的构建成本非常高,对知识库的质量要求非常高;框架的表达形式不灵活,很难同其它形式的数据集相互关联使用。

## 语义网络

​       语义网络是知识表示中最重要的方法之一，是一种表达能力强而且灵活的知识表示方法。语义网络利用节点和带标记的边结构的有向图描述事件、概念、状况、动作及客体之间的关系。带标记的有向图能十分自然的描述客体之间的关系。

​         语义网络由于其自然性而被广泛应用。采用语义网络表示的知识库的特征是利用带标记的有向图描述可能事件。结点表示客体、客体性质、概念、事件、状况和动作，带标记的边描述客体之间的关系。知识库的修改是通过插入和删除客体及其相关的关系实现的。采用网络表示法比较合适的领域大多数是根据非常复杂的分类进行推理的领域以及需要表示事件状况、性质以及动作之间的关系的领域。

​        语义网络的基本形式为(节点， 弧，  节点2)，节点表示各种事物、概念、情况、属性、动作、状态等，每个节点可以带有若干属性，一般用框架或元组表示。此外节点还可以是一个语义子网络，形成一个多层次的嵌套结构。语义网络中的弧表示各种语义联系，指明它所连接的节点间某种语义关系。节点和弧都必须带有标示，来方便区分不同对象以及对象间各种不同的语义联系。一个语义网络的例子为：

![img](pelhans.assets/v2-417cedbad03a10f7fb7df0fd39040054_720w.jpg)

**本质上是将逻辑运算符和逻辑项映射到了图中的元素**。语义网络具有以下优点：  

\- 把各个节点之间的联系以明确、简洁的方式表示出来，是一种直观的表示方法；  

\- 着重强调事物间的语义联系，体现了人类思维的联想过程，符合人们表达事物间的关系，因此把自然语言转换成语义网络较为容易;  

\- 具有广泛的表示范围和强大的表示能力，用其他形式的表示方法能表达的知识几乎都可以用语义网络来表示；  

\- 把事物的属性以及事物间的各种语义联系显示地表示出来，是一种结构化的知识表示法。

但语义网络也具有以下缺点：  

\- 推理规则不十分明了，不能充分保证网络操作所得推论的严格性和有效性；  

\- 一旦节点个数太多，网络结构复杂，推理就难以进行；  

\- 不便于表达判断性知识与深层知识。

## 基于语义网的知识表示框架

![img](pelhans.assets/v2-eed10b11fd02e5c14da59a2960202804_720w.jpg)

​        上图为W3C推荐的语义网标准栈，其中RDF和SPARQL为网络数据链接部分。与此同时，W3C还推出五星级标准，规定了RDF为标准数据格式，URI标准为事物命名等规范。

## RDF简介

## RDF概念

​        资源描述框架(Resource Description Framework，  RDF)，R代表页面，图片、视频等任何具有URI标识符，D标识属性、特征和资源之间的关系，F标识模型、语言和这些描述的语法。在RDF中，知识总是以三元组的形式出现，即每一份知识都可以被分解为：(subject, predicate, object)。

![[公式]](pelhans.assets/equation) 

​        与此同时，RDF三元组可以看做是图模型的边和顶点 ![[公式]](pelhans.assets/equation-20200904171713670) ,还可以将两个三元组结合起来表示：

![img](pelhans.assets/v2-317074406f575f562ca0ab21e540c0ff_720w.jpg)

​        在RDF中resource和properties是以URIs的形式表示的，如  。这样我们的表示就变成了这样：

![img](pelhans.assets/v2-8320b2bfa7edf700c87041c315014616_720w.jpg)

​        再结合URI的表示，我们可以把它简化为：

![img](pelhans.assets/v2-f18065e9d5a06ef7db2fed5bef09f097_720w.jpg)

​        在RDF中，properties的值可以是literals，如字符串，因此也可以长成：

![img](pelhans.assets/v2-f4d1a5e4c239cda78049c96f3aa2501d_720w.jpg)

​         properties还可以是XML类型的，因此还可以长成：

![img](pelhans.assets/v2-18ebe52d79cbe5458184a423d65d3095_720w.jpg)

## RDF和RDFS

​        **RDFS(RDF Schema)在RDF的基础上提供了一个术语、概念的定义方式，以及那些属性可以应用到哪些对象上**。换句话说，RDFS为RDF模型提供了一个基本的类型系统。如：

![img](pelhans.assets/v2-cefff2fa954166e7cd6fa5588056b364_720w.jpg)

​        上述三元组表示用户自定义的元数据Author是Dublin Core的元数据Creator的子类。RDF Schema正是通过这样的方式来描述不同词汇集的元数据之间的关系,从而为网络上统一格式的元数据交换打下基础。

RDFS支持推理功能，如：

![img](pelhans.assets/v2-2e388fc01554f2b916e1e976c966a32f_720w.jpg)

## OWL和OWL2

​         前面我们知道，通过RDF(S)可以表达一些简单的语义，但在更复杂的场景下，RDF(S)语义表达能力显得太弱，还缺少诸多常用的特征。包括对局部值域的属性定义，类、属性、个体的等价性，不相交类的定义，基数约束，关于属性特征的描述等。因此W3C提出了OWL语言扩展RDF(S)，作为语义网上表示本体的推荐语言。

## OWL

​        W3C于2002年7月31日发布了OWL Web本体语言(OWL Web Ontology  Language)工作草案的细节其目的是为了更好地开发语义网。OWL有三个子语言：OWL Lite、OWL DL、OWL  Full。下表给出OWL三个子语言的特征于区别：

![img](pelhans.assets/v2-05d84d410dfa3e53433eaf5ba87818d1_720w.jpg)

## OWL各语言如何选择

- 选择OWL Lite还是OWL DL主要取决于用户需要整个语言在多大程度上给出约束的可表达性;    
- 选择OWL DL还是OWL Full主要取决于用户在多大程度上需要RDF的元模型机制 (如定义类型的类型以及为类型赋予属性);    
- 在使用OWL Full而不是OWL DL时,推理的支持可能不能工作,因为目前还没有完全的支持OWL Full的系统实现。

​         综上所述，在要求简单是可采用OWL Lite，通常可采用OWL DL，对概念要求定义精确时采用OWL Full。(在Protege练习中感觉DL 和 Full区别并不明显)

## OWL与RDF的关系

- OWL Full可以看成是RDF的扩展;    
- OWL Lite和OWL Full可以看成是一个约束化的RDF的扩展;    
- 所有的OWL文档 (Lite,DL,Full)都是一个RDF文档;    
- 所有的RDF文档都是一个OWL Full文档;    
- 只有一些RDF文档是一个合法的OWL Lite和OWL DL文档。

​        上面说的很模糊，在Protege操作中，OWL给我的感觉就是在RDFS的基础上，添加了很多描述类别、属性之间关系的定义或约束。,如两个类是否不相交这样的类属性。

## OWL词汇扩展

![img](pelhans.assets/v2-11f099c8d1a1bc69e43f53cfc36b391f_720w.jpg)

## OWL2

​        OWL2是OWL的最新版本，老的OWL也称为OWL1，OWL2定义了一些OWL的子语言,通过限制语法使用,使得这些子语言能够更方便地实现,以及服务于不同的应用;OWL2也有三大子语言：OWL2 RL，OWL2 QL， OWL2 EL；

![img](pelhans.assets/v2-a6345af391d5a6032a8394be870f4c97_720w.jpg)

​        OWL2 QL适合概念多的情况，OWL2 EL适合实例较多的情况，如医学领域，OWL2 RL适合高效推理。

## OWL2 QL

QL代表query language的意思,专为基于本体的查询设计:  

\- OWL 2 QL的复杂度是AC 0 ,非常适合大规模处理;  

\- OWL 2的三大子语言中,QL最为简单;  

\- OWL 2 QL是基于描述逻辑语言DL-Lite定义的。

OWL2 QL允许的核心词汇为：

![img](pelhans.assets/v2-a72b66793a3f2789f3808eff685e0564_720w.jpg)

​        通过OWL 2 QL的语言限制,基于QL的本体查询可以优化到多项式对数时间复杂度。

![img](pelhans.assets/v2-9080300c32e573e811ccc65ad3ef27e3_720w.jpg)

## OWL2 EL

OWL 2 EL专为概念术语描述,推理而设计:

- 在生物医疗领域广泛应用,如临床医疗术语本体SNOMED CT;    
- 复杂度是PTime-Complete；    
- OWL2 EL是基于描述逻辑语言EL++定义的；

它允许的核心词汇为:

![img](pelhans.assets/v2-36fdcbdef6f54dbec02cf87433b99063_720w.jpg)

OWL2 EL允许表达复杂的概念，如

![[公式]](pelhans.assets/equation?tex=Female+%E2%8A%93+%E2%88%83likes.Movie+%E2%8A%93+%E2%88%83hasSon.(Student+%E2%8A%93+%E2%88%83attends.CSCourse+)) 

## OWL2 RL

OWL 2 RL在ter Horst的工作基础上延伸而来;  该工作的目的是将OWL词汇引入RDFS,使得RDFS在表达能力上丰富起来,同时保持计算复杂度在PTime级别。OWL 2  RL在RDFS的基础上引入属性的特殊特性 (函数性,互反性,对称性);允许声明等价性;允许属性的局部约束。OWL 2  RL与描述逻辑没有直接关系。

业界的一种观点是,OWL 2 RL是专为高效推理设计的本体语言(推理针对的是实例数据)。

OWL2 RL允许的核心词汇为：

![img](pelhans.assets/v2-cfe8a39e4e6d00833966929074d0d1a1_720w.jpg)

## OWL2的推理系统

![img](pelhans.assets/v2-1f3b5b380cb668238b0d4981c459b9f1_720w.jpg)

## SPARQL简介

​        SPARQL是RDF的查询语言，它基于RDF数据模型，可以对不同的数据集撰写复杂的连接，同时还被所有主流的图数据库支持。

​        SPARQL的查询结构如下图所示：

![img](pelhans.assets/v2-f22ee540f2b1baf7dc5295c719d24176_720w.jpg)

​        从语法上结构上来看，SPARQL和SQL语言还是有一定的相似性的。比较重要的区别有：

- 变量,RDF中的资源,以“?”或者“$”指示；    
- 三元组模板 (triple pattern), 在WHERE子句中列示关联的三元组模板,之所以称之为模板,因为三元组中允许变量;    
- SELECT子句中指示要查询的目标变量    

​        有关SPARQL的详细操作指令我打算在实战单开一个小结把重要操作演示一遍。这里仅给出一个小例子看操作是什么样子的：

![img](pelhans.assets/v2-07579131b5d7481721ce5eb3d5c4cc51_720w.jpg)

## JSON-LD

​        为了方便程序员阅读知识标识，出现了JSON-LD，JSON-LD是JavaScript Object Notation for  Linked Data的缩写,是一种基于JSON表示和传输互联数据 (Linked  Data)的方法。JSON-LD描述了如何通过JSON表示有向图,以及如何在一个文档中混合表示互联数据及非互联数据。JSON-LD的语法和JSON兼容。

​         JSON-LD呈现出语义网技术的风格,它们有着类似的目标:围绕某类知识提供共享的术语。例如,每个数据集不应该围绕“name”重复发明概念。JSON-LD 的 实 现 没 有 选 择 大 部 分 语 义 网 技 术 栈 (Turtle/SPARQL/Quad  Stores)而是以简单、不复杂以及面向一般开发人员的方式推进。下图给出JSON-LD事例，可以看出非常容易理解:

![img](pelhans.assets/v2-b39f00384006098a7fdc4306cc6c8d14_720w.jpg)

## RDFa

​        RDFa(Resource Description Framework in attributes)是网页标记语言，也是W3C推荐的标准，它**扩充了XHTML的几个属性**,网页制作者可以利用这些属性在网页中添加可供机器读取的资源。与RDF的对应关系使得RDFa可以将RDF的三元组嵌入在XHTML文档中,它也使得符合标准的使用端可以从RDFa文件中提取出这些RDF三元组来。**RDFa从机器可理解的层面优化搜索,提升访问性以及网页数据的关联性**。

![img](pelhans.assets/v2-5365e593c1c244540a0fd58c3b94f02b_720w.jpg)

## HTML5 Microdata

​        Microdata微数据,是在网页标记标记语言嵌入机器可读的属性数据，微数据使用可以来自自定义词汇表、带作用域的键/值对给DOM做标记。用户可以自定义微数据词汇表,在自己的网页中嵌入自定义的属性。微数据是给那些已经在页面上可见的数据施加额外的语义。当HTML的词汇不够用时,使用微数据可以取得较好的效果。

![img](pelhans.assets/v2-57dbd2c97a4503a379ba197b45d05654_720w.jpg)

## Ref

[王昊奋知识图谱教程](https://link.zhihu.com/?target=http%3A//www.chinahadoop.cn/course/1048)



# (三)   知识抽取



欢迎大家关注我的博客 [http://pelhans.com/](https://link.zhihu.com/?target=http%3A//pelhans.com/) ，所有文章都会第一时间发布在那里哦~

------



> 本节介绍了针对结构化数据、非结构化数据、半结构化数据的知识抽取方法。

## 知识抽取的概念

​        知识抽取，即从不同来源、不同结构的数据中进行知识提取，形成知识(结构化数据)存入到知识图谱。大体的任务分类与对应技术如下图所示：

![img](pelhans.assets/v2-ea3fb24f4785ec4635cadd5023f25173_720w.jpg)

## 知识抽取的子任务

- 命名实体识别    

- - 检测: 北京是忙碌的城市。        [北京]： 实体
  - 分类：北京是忙碌的城市。        [北京]:  地名    

- 术语抽取  
  从语料中发现多个单词组成的相关术语。    

- 关系抽取  
  王思聪是万达集团董事长王健林的独子。 ![[公式]](pelhans.assets/equation-20200904171803869) [王健林] <父子关系> [王思聪]    

- 事件抽取  
  例如从一篇新闻报道中抽取出事件发生是触发词、时间、地点等信息，如图二所示。    

- 共指消解  
  弄清楚在一句话中的代词的指代对象。例子如图3所示。

![img](pelhans.assets/v2-f60c60fe79fc8449a415e412d659e3a5_720w.jpg)

![img](pelhans.assets/v2-9c3025a9ab10c3884affd95d4e1fa9df_720w.jpg)图3

## 面向非结构化数据的知识抽取

## 实体抽取

​        实体抽取抽取文本中的原子信息元素，通常包含任命、组织/机构名、地理位置、时间/日期、字符值等标签，具体的标签定义可根据任务不同而调整。如：

![img](pelhans.assets/v2-549c56ea13ad63a9b0804990298e70dd_720w.jpg)

​        单纯的实体抽取可作为一个序列标注问题，因此可以使用机器学习中的HMM、CRF、神经网络等方法解决。

## 实体识别与链接

​       实体识别即识别出句子或文本中的实体，链接就是将该实体与知识库中的对应实体进行链接。其中涉及到了实体的识别与消岐技术。实体识别技术刚刚介绍过，下面把重点放在实体链接部分。

​        实体链接的流程如下图所示：

![img](pelhans.assets/v2-7fe730d5624bf1dae9b48699445c61ef_720w.jpg)

​         文字表述为，首先输入的是非结构化的文本数据，经由命名实体识别或词典匹配技术进行实体的指称识别。由于刚刚识别出来的实体可能是实体的部分表示或另类表示，因此需要结束表层名字扩展、搜索引擎、构建查询实体引用表等技术来对候选实体进行生成。经过该步骤生成的实体可能有多个候选项，因此需要对候选实体进行消岐，此处可使用基于图的方法、基于概率生成模型、基于主题模型或基于深度学习的方法。经过实体消岐后得到的唯一实体候选后就可以与知识库中的实体进行连接了。

​        举个例子：

![img](pelhans.assets/v2-b9d07b23b2036beec05435ff041c80c1_720w.jpg)

## 关系抽取

​        关系抽取是从文本中抽取出两个或多个实体之间的语义关系。它是信息抽取研究领域的任务之一。如:  
\- 王健林谈儿子王思聪:我期望他稳重一点。  
​    \- 父子 (王健林, 王思聪)

​        根据关系抽取方法的不同，可以将其分为:基于模板的方法(触发词的Pattern, 依存句法分析的Pattern)、基于监督学习的方法(机器学习方法)、弱监督学习的方法(远程监督、Bootstrapping)。

## 基于模板的方法

​         基于模板的方法在小规模数据集上容易实现且构建简单，缺点为难以维护、可移植性差、模板有可能需要专家构建。

## 基于触发词的Pattern

​        首先定义一套种子模板，如：

![img](pelhans.assets/v2-3a6ebbe61b7c3fb47dea300c372b2e20_720w.jpg)

​        其中的触发词为老婆、妻子、配偶等。根据这些触发词找出夫妻关系这种关系，同时通过命名实体识别给出关系的参与方。

## 基于依存分析的Pattern

​        以动词为起点，构建规则，对节点上的词性和边上的依存关系进行限定。一般情况下是形容词+名字或动宾短语等情况，因此相当于以动词为中心结构做的Pattern。其执行流程为:

![img](pelhans.assets/v2-18fd2e5ab1d45d171b3738a1ce3388e6_720w.jpg)

## 监督学习

​        在给定实体对的情况下，根据句子上下文对实体关系进行预测，执行流程为：

- 预先定义好关系的类别。    
- 人工标注一些数据。    
- 设计特征表示。    
- 选择一个分类方法。(SVM、NN、朴素贝叶斯)    
- 评估方法。

​        其优点为准确率高，标注的数据越多越准确。缺点为标注数据的成本太高，不能扩展新的关系。

## Pipeline训练

​        即识别实体和关系分类是完全分离的两个过程,不会相互影响,关系的识别依赖于实体识别的效果，这样的好处的各模型相互独立，设计上较为容易，但误差会逐层传递，步骤太多有可能导致后续不可用。

![img](pelhans.assets/v2-3a7624530434a4d835bb3f742d996bba_720w.jpg)

## 联合模型

​        将实体识别和关系分类一起做，在一个模型中完成。

## 半监督学习方法

​        前面的监督学习效果虽好，但有标注数据集的获取困难。因此可以借助半监督学习的方法，此处又分为远程监督学习和Bootstrapping方法两种。

​        所谓远程监督方法就是知识库与非结构化文本对齐来自动构建大量训练数据,减少模型对人工标注数据的依赖,增强模型跨领域适应能力。Bootstrapping是通过在文本中匹配实体对和表达关系短语模式,寻找和发现新的潜在关系三元组。

## 远程监督

​         该方法认为若两个实体如果在知识库中存在某种关系,则包含该两个实体的非结构化句子均能表示出这种关系。如在某知识库中存在“创始人(乔布斯，苹果公司)”。那么就认为出现乔布斯和苹果公司的句子就是表述创始人这项关系。因此可构建训练正例：乔布斯是苹果公司的联合创始人和CEO。

远程监督流程为：
\- 从知识库中抽取存在关系的实体对。  
\- 从非结构化文本中抽取含有实体对的句子作为训练样例。

​       远程监督可以利用丰富的知识库信息，减少一定的人工标注，但它的假设过于肯定，如乔布斯被赶出苹果公司。这句话表达的就不是创始人的例子，因此会引入大量的噪声，存在语义漂移现象。同时由于是在知识库中抽取存在的实体关系对，因此很难发现新的关系。

## Bootstrapping

​        这个方法在很多任务中都有提到，其执行流程为：

- 1.从文档中抽取出包含种子实体的新闻，如：

- - 姚明老婆 叶莉 简历身高曝光  
        X 老婆 Y 简历身高曝光
  - 姚明 与妻子 叶莉 外出赴约  
        X 与妻子 Y 外出赴约    

- 将抽取出的Pattern去文档集中匹配 

- - 小猪 与妻子 伊万 外出赴约

- 根据Pattern抽取出的新文档如种子库,迭代多轮直到不符合条件

​        该方法的优点为构建成本低，适合大规模的构建，同时还可以发现新的(隐含的)关系。缺点为对初始给定的种子集敏感，存在语义漂移现象，结果的准确率较低等。

## 事件抽取

从自然语言中抽取出用户感兴趣的事件信息,并以结构化的形式呈现出来,例如事件发生的时间、地点、发生原因、参与者等。如：

![img](pelhans.assets/v2-f8a7d6771540e17d048beab5d0eb289b_720w.jpg)

​        事件抽取任务最基础的部分包括：  
​            \- 识别事件触发词及事件类型  
​            \- 抽取事件元素同时判断其角色  
​            \- 抽出描述事件的词组或句子    

​        此外，事件抽取任务还包括：  
​            \- 事件属性标注  
​            \- 事件共指消解

对于事件抽取，也可分为Pipeline方法和联合训练的方法。

## 事件抽取的pipeline方法

​        有监督的事件抽取方法的标准流程一种pipeline的方法,将事件抽取任务转化为多阶段的分类问题,需要的分类器包括:  
\- 事件触发次分类器(Trigger Classifier)  
​    \- 用于判断词汇是否是是事件触发词,以及事件的类别  
\- 元素分类器(Argument Classifier)  
​    \- 判别词组是否是事件的元素  
\- 元素角色分类器(Role Classifier)  
​    \- 判定元素的角色类别  
\- 属性分类器(attribute classifier)  
​    \- 判定事件的属性  
\- 可报告性分类器(Reportable-Event Classifier)  
​    \- 判定是否存在值得报告的事件实例

​        可以看到，这个流程还是蛮长的，因此Pipeline存在的误差传递问题在这里格外严重，因此我们需要联合训练：

![img](pelhans.assets/v2-a97b1eb07e6c3801847dc619f5165c24_720w.jpg)

## 联合训练

![img](pelhans.assets/v2-151eb881439284d6da5a6e570b80c214_720w.jpg)

## 基于深度学习的事件抽取方法

​        传统的方法需要借助外部NLP工具，还需要人工设计特征，但深度学习可以自动提取句子特征，减少对外部NLP工具的依赖。

​        下图给出一个典型的基于动态多池化卷积神经网络的事件抽取方法：

![img](pelhans.assets/v2-8942303273712aa14c69dbeb90f252e7_720w.jpg)

## 面向结构化数据的知识抽取

​         所谓结构化数据就是指类似于关系库中表格那种形式的数据，他们往往各项之间存在明确的关系名称和对应关系。因此我们可以简单的将其转化为RDF或其他形式的知识库内容。一种常用的W3C推荐的映射语言是R2RML(RDB2RDF)。一种映射结果如下图所示：

![img](pelhans.assets/v2-f5625cf7906703ae98c1b2c0c4deeada_720w.jpg)

​        现有的工具免费的有D2R，Virtuoso、MOrph等。

## 面向半结构化数据的知识抽取

​        半结构化数据是指类似于百科、商品列表等那种本身存在一定结构但需要进一步提取整理的数据。

## 百科类知识抽取

​        对于百科类数据我们都较为熟悉，下图介绍怎么从百科里抽取知识：

![img](pelhans.assets/v2-388f8b66a693ac1dbfca5ed15399ba8d_720w.jpg)

​        上图给出从百科里抽取知识的流程介绍。(**待补**)

## Web网页数据抽取：包装器生成

​        现在我们的目标网站是部分结构化的，如：

![img](pelhans.assets/v2-2fec47df3461212ae8456b2e2d60fd05_720w.jpg)

​        包装器是一个能够将数据从HTML网页中抽取出来,并且将它们还原为结构化的数据的软件程序。使用它提取信息流程为：

![img](pelhans.assets/v2-92d7d66a1784b3062f985d07e5d02031_720w.jpg)

## 包装器归纳

​         对于一般的有规律的页面，我们可以使用正则表达式的方式写出XPath和CSS选择器表达式来提取网页中的元素。但这样的通用性很差，因此也可以通过包装器归纳这种基于有监督学习的方法,自动的从标注好的训练样例集合中学习数据抽取规则,用于从其他相同标记或相同网页模板抽取目标数据。其运行流程为：

![img](pelhans.assets/v2-17c609f38267d6ecdfb51a0ce4118b60_720w.jpg)

## 自动抽取

​         对于监督学习我们知道标注数据是它的短板，因此我们想到自动抽取的方法。网站中的数据通常是用很少的一些模板来编码的,通过挖掘多个数据记录中的重复模式来寻找这些模板是可能的。自动抽取的流程如图所示：

![img](pelhans.assets/v2-94f9a44df0d47a9ae6e2dc4d033f716b_720w.jpg)

## Ref

[王昊奋知识图谱教程](https://link.zhihu.com/?target=http%3A//www.chinahadoop.cn/course/1048)

发布于 2018-07-07





# END